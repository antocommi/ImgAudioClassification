{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "audio_clf2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFSj7y2aHdHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install librosa\n",
        "import os\n",
        "from PIL import Image\n",
        "import librosa\n",
        "import glob\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# image MFCC 128x44"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGsdai8kKKtQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "outputId": "90e3bc76-37a1-420c-9ccb-4749717fa1e1"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.2.0\n",
            "Running on TPU  ['10.83.13.66:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.83.13.66:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.83.13.66:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmS55Pdz6ka8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "34214c41-e96b-474b-ef9d-6abd5805ba1f"
      },
      "source": [
        "dataset_path = \"/content/drive/My Drive/img.pkl\"\n",
        "res = pd.read_pickle(dataset_path)\n",
        "x = res.drop([\"y\"], axis=1)                     \n",
        "y = res['y']\n",
        "print(x.shape,y.shape)\n",
        "max_data = np.max(x)\n",
        "min_data = np.min(x)\n",
        "data = (x-min_data)/(max_data-min_data+1e-6)\n",
        "data =  data-0.5\n",
        "print(\"Normalization done!\")\n",
        "x = data.to_numpy().reshape(data.shape[0],128,44,1)\n",
        "y = y.to_numpy()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(52117, 5632) (52117,)\n",
            "Normalization done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyV952qY7QPg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3f81a59c-4784-4100-9cf3-d5fcfa81f7ec"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "mode = \"sequential\"\n",
        "\n",
        "if mode==\"sequential\":\n",
        "    x = x.reshape(data.shape[0],128*44)\n",
        "else:\n",
        "    x = x.reshape(data.shape[0],128,44,1)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y,\n",
        "                                                   test_size=0.8,\n",
        "                                                   shuffle=True,\n",
        "                                                   random_state=8735,\n",
        "                                                   stratify=y)\n",
        "print(\"done!\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM6GUt1iydyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "cntTrain = np.bincount(y_train)\n",
        "max = np.max(cntTrain)\n",
        "res = cntTrain / max\n",
        "print(res.min(),res.max(),res.mean(), res[0:5])\n",
        "matplotlib.pyplot.plot([res,res+0.1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCGC-PQ3qYh2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "37eb0cd4-17c0-4e8e-e84f-289cb8ff2c91"
      },
      "source": [
        "# model = keras.models.Sequential()\n",
        "# model.add(keras.layers.Flatten(shape=(60*80,)))\n",
        "# model.add(keras.layers.Dense(3000, activation=\"relu\"))\n",
        "# model.add(keras.layers.Dense(50, activation=\"relu\"))\n",
        "# model.add(keras.layers.Dense(20, activation=\"relu\"))\n",
        "# model.add(keras.layers.Dense(4, activation=\"softmax\"))\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "def getNewModel():\n",
        "  model = keras.models.Sequential()\n",
        "  input_shape=(x.shape[1],x.shape[2],1)\n",
        "  model.add(keras.layers.Conv2D(32, (3, 3), strides=(2, 2), input_shape=input_shape))\n",
        "  model.add(keras.layers.AveragePooling2D((2, 2), strides=(2,2)))\n",
        "  model.add(keras.layers.Activation('relu'))\n",
        "  model.add(keras.layers.Conv2D(64, (3, 3), padding=\"same\"))\n",
        "  model.add(keras.layers.AveragePooling2D((2, 2), strides=(2,2)))\n",
        "  model.add(keras.layers.Activation('relu'))\n",
        "  model.add(keras.layers.Conv2D(64, (3, 3), padding=\"same\"))\n",
        "  model.add(keras.layers.AveragePooling2D((2, 2), strides=(2,2)))\n",
        "  model.add(keras.layers.Activation('relu'))\n",
        "  model.add(keras.layers.Flatten())\n",
        "  model.add(keras.layers.Dropout(rate=0.5))\n",
        "  model.add(keras.layers.Dense(64))\n",
        "  model.add(keras.layers.Activation('relu'))\n",
        "  model.add(keras.layers.Dropout(rate=0.5))\n",
        "  model.add(keras.layers.Dense(30))\n",
        "  model.add(keras.layers.Activation('softmax'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB52kAm7qln2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eb13550f-8ded-41a7-f57a-187ef5f1ec32"
      },
      "source": [
        "from numpy import array\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# def kfoldcv(classifier):\n",
        "kf = KFold(n_splits=10,shuffle=True,random_state=43)\n",
        "kf.get_n_splits(x) \n",
        "scores = []\n",
        "modelli = []\n",
        "for train_index, test_index in kf.split(x):\n",
        "    print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index), end=\" \")\n",
        "    x_train_cv, x_test_cv = x[train_index], x[test_index]\n",
        "    y_train_cv, y_test_cv = y[train_index], y[test_index]\n",
        "    # clf = classifier.fit(x_train_cv,y_train_cv)\n",
        "    model = getNewModel()\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
        "    model.fit(x_train_cv,  y_train_cv, epochs=65)\n",
        "    s = model.evaluate(x_test_cv, y_test_cv, verbose=0)\n",
        "    scores.append(s)\n",
        "    modelli.append(model)\n",
        "    print(s)\n",
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN: 46905 TEST: 5212 Epoch 1/65\n",
            "46905/46905 [==============================] - 35s 744us/step - loss: 3.3952 - accuracy: 0.0390\n",
            "Epoch 2/65\n",
            "46905/46905 [==============================] - 34s 735us/step - loss: 3.3876 - accuracy: 0.0458\n",
            "Epoch 3/65\n",
            "46905/46905 [==============================] - 35s 749us/step - loss: 3.3743 - accuracy: 0.0540\n",
            "Epoch 4/65\n",
            "46905/46905 [==============================] - 35s 743us/step - loss: 3.3223 - accuracy: 0.0718\n",
            "Epoch 5/65\n",
            "46905/46905 [==============================] - 35s 751us/step - loss: 3.1561 - accuracy: 0.1052\n",
            "Epoch 6/65\n",
            "46905/46905 [==============================] - 35s 736us/step - loss: 2.9024 - accuracy: 0.1578\n",
            "Epoch 7/65\n",
            "46905/46905 [==============================] - 34s 735us/step - loss: 2.6912 - accuracy: 0.2087\n",
            "Epoch 8/65\n",
            "46905/46905 [==============================] - 34s 731us/step - loss: 2.5440 - accuracy: 0.2479\n",
            "Epoch 9/65\n",
            "46905/46905 [==============================] - 34s 720us/step - loss: 2.4296 - accuracy: 0.2794\n",
            "Epoch 10/65\n",
            "46905/46905 [==============================] - 34s 731us/step - loss: 2.3356 - accuracy: 0.3078\n",
            "Epoch 11/65\n",
            "46905/46905 [==============================] - 34s 718us/step - loss: 2.2490 - accuracy: 0.3305\n",
            "Epoch 12/65\n",
            "46905/46905 [==============================] - 34s 715us/step - loss: 2.1739 - accuracy: 0.3532\n",
            "Epoch 13/65\n",
            "46905/46905 [==============================] - 35s 741us/step - loss: 2.0957 - accuracy: 0.3731\n",
            "Epoch 14/65\n",
            "46905/46905 [==============================] - 35s 740us/step - loss: 2.0230 - accuracy: 0.3936\n",
            "Epoch 15/65\n",
            "46905/46905 [==============================] - 35s 755us/step - loss: 1.9658 - accuracy: 0.4089\n",
            "Epoch 16/65\n",
            "46905/46905 [==============================] - 34s 728us/step - loss: 1.8984 - accuracy: 0.4281\n",
            "Epoch 17/65\n",
            "46905/46905 [==============================] - 34s 723us/step - loss: 1.8433 - accuracy: 0.4462\n",
            "Epoch 18/65\n",
            "46905/46905 [==============================] - 35s 738us/step - loss: 1.7849 - accuracy: 0.4644\n",
            "Epoch 19/65\n",
            "46905/46905 [==============================] - 34s 719us/step - loss: 1.7183 - accuracy: 0.4826\n",
            "Epoch 20/65\n",
            "46905/46905 [==============================] - 35s 736us/step - loss: 1.6698 - accuracy: 0.4971\n",
            "Epoch 21/65\n",
            "46905/46905 [==============================] - 34s 725us/step - loss: 1.6263 - accuracy: 0.5056\n",
            "Epoch 22/65\n",
            "46905/46905 [==============================] - 34s 734us/step - loss: 1.5713 - accuracy: 0.5230\n",
            "Epoch 23/65\n",
            "46905/46905 [==============================] - 34s 726us/step - loss: 1.5400 - accuracy: 0.5332\n",
            "Epoch 24/65\n",
            "46905/46905 [==============================] - 35s 744us/step - loss: 1.5064 - accuracy: 0.5409\n",
            "Epoch 25/65\n",
            "46905/46905 [==============================] - 34s 726us/step - loss: 1.4704 - accuracy: 0.5524\n",
            "Epoch 26/65\n",
            "46905/46905 [==============================] - 35s 741us/step - loss: 1.4438 - accuracy: 0.5606\n",
            "Epoch 27/65\n",
            "46905/46905 [==============================] - 33s 705us/step - loss: 1.4111 - accuracy: 0.5696\n",
            "Epoch 28/65\n",
            "46905/46905 [==============================] - 34s 729us/step - loss: 1.3855 - accuracy: 0.5779\n",
            "Epoch 29/65\n",
            "46905/46905 [==============================] - 34s 735us/step - loss: 1.3574 - accuracy: 0.5861\n",
            "Epoch 30/65\n",
            "46905/46905 [==============================] - 34s 735us/step - loss: 1.3371 - accuracy: 0.5954\n",
            "Epoch 31/65\n",
            "46905/46905 [==============================] - 34s 726us/step - loss: 1.3140 - accuracy: 0.6028\n",
            "Epoch 32/65\n",
            "46905/46905 [==============================] - 35s 745us/step - loss: 1.3041 - accuracy: 0.6010\n",
            "Epoch 33/65\n",
            "46905/46905 [==============================] - 34s 723us/step - loss: 1.2847 - accuracy: 0.6121\n",
            "Epoch 34/65\n",
            "46905/46905 [==============================] - 34s 724us/step - loss: 1.2670 - accuracy: 0.6164\n",
            "Epoch 35/65\n",
            "46905/46905 [==============================] - 33s 709us/step - loss: 1.2516 - accuracy: 0.6206\n",
            "Epoch 36/65\n",
            "46905/46905 [==============================] - 35s 736us/step - loss: 1.2311 - accuracy: 0.6247\n",
            "Epoch 37/65\n",
            "46905/46905 [==============================] - 35s 739us/step - loss: 1.2165 - accuracy: 0.6323\n",
            "Epoch 38/65\n",
            "46905/46905 [==============================] - 34s 724us/step - loss: 1.2101 - accuracy: 0.6345\n",
            "Epoch 39/65\n",
            "46905/46905 [==============================] - 33s 702us/step - loss: 1.1941 - accuracy: 0.6368\n",
            "Epoch 40/65\n",
            "46905/46905 [==============================] - 33s 714us/step - loss: 1.1761 - accuracy: 0.6423\n",
            "Epoch 41/65\n",
            "46905/46905 [==============================] - 34s 724us/step - loss: 1.1592 - accuracy: 0.6450\n",
            "Epoch 42/65\n",
            "46905/46905 [==============================] - 34s 724us/step - loss: 1.1520 - accuracy: 0.6519\n",
            "Epoch 43/65\n",
            "46905/46905 [==============================] - 34s 728us/step - loss: 1.1402 - accuracy: 0.6534\n",
            "Epoch 44/65\n",
            "46905/46905 [==============================] - 34s 730us/step - loss: 1.1325 - accuracy: 0.6561\n",
            "Epoch 45/65\n",
            "46905/46905 [==============================] - 34s 730us/step - loss: 1.1218 - accuracy: 0.6614\n",
            "Epoch 46/65\n",
            "46905/46905 [==============================] - 34s 731us/step - loss: 1.1078 - accuracy: 0.6639\n",
            "Epoch 47/65\n",
            "46905/46905 [==============================] - 34s 714us/step - loss: 1.1018 - accuracy: 0.6661\n",
            "Epoch 48/65\n",
            "46905/46905 [==============================] - 34s 735us/step - loss: 1.0910 - accuracy: 0.6690\n",
            "Epoch 49/65\n",
            "46905/46905 [==============================] - 33s 713us/step - loss: 1.0920 - accuracy: 0.6695\n",
            "Epoch 50/65\n",
            "46905/46905 [==============================] - 33s 707us/step - loss: 1.0642 - accuracy: 0.6770\n",
            "Epoch 51/65\n",
            "46905/46905 [==============================] - 33s 712us/step - loss: 1.0591 - accuracy: 0.6786\n",
            "Epoch 52/65\n",
            "46905/46905 [==============================] - 35s 740us/step - loss: 1.0641 - accuracy: 0.6779\n",
            "Epoch 53/65\n",
            "46905/46905 [==============================] - 34s 717us/step - loss: 1.0481 - accuracy: 0.6827\n",
            "Epoch 54/65\n",
            "46905/46905 [==============================] - 34s 720us/step - loss: 1.0410 - accuracy: 0.6839\n",
            "Epoch 55/65\n",
            "46905/46905 [==============================] - 34s 729us/step - loss: 1.0283 - accuracy: 0.6883\n",
            "Epoch 56/65\n",
            "46905/46905 [==============================] - 34s 715us/step - loss: 1.0199 - accuracy: 0.6918\n",
            "Epoch 57/65\n",
            "46905/46905 [==============================] - 33s 706us/step - loss: 1.0173 - accuracy: 0.6917\n",
            "Epoch 58/65\n",
            "46905/46905 [==============================] - 33s 710us/step - loss: 1.0103 - accuracy: 0.6942\n",
            "Epoch 59/65\n",
            "46905/46905 [==============================] - 34s 716us/step - loss: 1.0034 - accuracy: 0.6962\n",
            "Epoch 60/65\n",
            "46905/46905 [==============================] - 34s 732us/step - loss: 1.0017 - accuracy: 0.6962\n",
            "Epoch 61/65\n",
            "46905/46905 [==============================] - 35s 749us/step - loss: 0.9903 - accuracy: 0.6993\n",
            "Epoch 62/65\n",
            "46905/46905 [==============================] - 35s 737us/step - loss: 0.9812 - accuracy: 0.7023\n",
            "Epoch 63/65\n",
            "46905/46905 [==============================] - 34s 718us/step - loss: 0.9818 - accuracy: 0.7045\n",
            "Epoch 64/65\n",
            "46905/46905 [==============================] - 33s 705us/step - loss: 0.9736 - accuracy: 0.7048\n",
            "Epoch 65/65\n",
            "46905/46905 [==============================] - 33s 713us/step - loss: 0.9619 - accuracy: 0.7082\n",
            "[0.5928769217416678, 0.8294320702552795]\n",
            "TRAIN: 46905 TEST: 5212 Epoch 1/65\n",
            "46905/46905 [==============================] - 33s 709us/step - loss: 3.3952 - accuracy: 0.0375\n",
            "Epoch 2/65\n",
            "46905/46905 [==============================] - 32s 691us/step - loss: 3.3874 - accuracy: 0.0429\n",
            "Epoch 3/65\n",
            "46905/46905 [==============================] - 33s 696us/step - loss: 3.3729 - accuracy: 0.0501\n",
            "Epoch 4/65\n",
            "46905/46905 [==============================] - 33s 695us/step - loss: 3.3281 - accuracy: 0.0662\n",
            "Epoch 5/65\n",
            "46905/46905 [==============================] - 33s 707us/step - loss: 3.1974 - accuracy: 0.1006\n",
            "Epoch 6/65\n",
            "46905/46905 [==============================] - 32s 690us/step - loss: 2.9437 - accuracy: 0.1525\n",
            "Epoch 7/65\n",
            "46905/46905 [==============================] - 33s 700us/step - loss: 2.7095 - accuracy: 0.2070\n",
            "Epoch 8/65\n",
            "46905/46905 [==============================] - 32s 689us/step - loss: 2.5406 - accuracy: 0.2469\n",
            "Epoch 9/65\n",
            "46905/46905 [==============================] - 33s 695us/step - loss: 2.4017 - accuracy: 0.2882\n",
            "Epoch 10/65\n",
            "46905/46905 [==============================] - 32s 682us/step - loss: 2.2891 - accuracy: 0.3195\n",
            "Epoch 11/65\n",
            "46905/46905 [==============================] - 33s 693us/step - loss: 2.1822 - accuracy: 0.3515\n",
            "Epoch 12/65\n",
            "46905/46905 [==============================] - 33s 703us/step - loss: 2.0891 - accuracy: 0.3751\n",
            "Epoch 13/65\n",
            "46905/46905 [==============================] - 33s 701us/step - loss: 2.0044 - accuracy: 0.4014\n",
            "Epoch 14/65\n",
            "46905/46905 [==============================] - 33s 707us/step - loss: 1.9325 - accuracy: 0.4231\n",
            "Epoch 15/65\n",
            "46905/46905 [==============================] - 33s 702us/step - loss: 1.8528 - accuracy: 0.4455\n",
            "Epoch 16/65\n",
            "46905/46905 [==============================] - 33s 694us/step - loss: 1.7816 - accuracy: 0.4645\n",
            "Epoch 17/65\n",
            "46905/46905 [==============================] - 33s 695us/step - loss: 1.7231 - accuracy: 0.4825\n",
            "Epoch 18/65\n",
            "46905/46905 [==============================] - 32s 690us/step - loss: 1.6718 - accuracy: 0.4973\n",
            "Epoch 19/65\n",
            "46905/46905 [==============================] - 32s 692us/step - loss: 1.6167 - accuracy: 0.5121\n",
            "Epoch 20/65\n",
            "46905/46905 [==============================] - 32s 691us/step - loss: 1.5685 - accuracy: 0.5263\n",
            "Epoch 21/65\n",
            "46905/46905 [==============================] - 33s 695us/step - loss: 1.5194 - accuracy: 0.5404\n",
            "Epoch 22/65\n",
            "46905/46905 [==============================] - 32s 688us/step - loss: 1.4882 - accuracy: 0.5514\n",
            "Epoch 23/65\n",
            "46905/46905 [==============================] - 33s 698us/step - loss: 1.4527 - accuracy: 0.5603\n",
            "Epoch 24/65\n",
            "46905/46905 [==============================] - 34s 715us/step - loss: 1.4214 - accuracy: 0.5699\n",
            "Epoch 25/65\n",
            "46905/46905 [==============================] - 32s 690us/step - loss: 1.3926 - accuracy: 0.5811\n",
            "Epoch 26/65\n",
            "46905/46905 [==============================] - 32s 690us/step - loss: 1.3634 - accuracy: 0.5870\n",
            "Epoch 27/65\n",
            "46905/46905 [==============================] - 33s 699us/step - loss: 1.3398 - accuracy: 0.5906\n",
            "Epoch 28/65\n",
            "46905/46905 [==============================] - 32s 688us/step - loss: 1.3221 - accuracy: 0.6005\n",
            "Epoch 29/65\n",
            "46905/46905 [==============================] - 32s 693us/step - loss: 1.3004 - accuracy: 0.6065\n",
            "Epoch 30/65\n",
            "46905/46905 [==============================] - 32s 690us/step - loss: 1.2806 - accuracy: 0.6136\n",
            "Epoch 31/65\n",
            "46905/46905 [==============================] - 32s 690us/step - loss: 1.2612 - accuracy: 0.6181\n",
            "Epoch 32/65\n",
            "46905/46905 [==============================] - 33s 701us/step - loss: 1.2408 - accuracy: 0.6239\n",
            "Epoch 33/65\n",
            "46905/46905 [==============================] - 33s 705us/step - loss: 1.2276 - accuracy: 0.6284\n",
            "Epoch 34/65\n",
            "46905/46905 [==============================] - 33s 703us/step - loss: 1.2095 - accuracy: 0.6338\n",
            "Epoch 35/65\n",
            "46905/46905 [==============================] - 33s 707us/step - loss: 1.1957 - accuracy: 0.6383\n",
            "Epoch 36/65\n",
            "46905/46905 [==============================] - 33s 704us/step - loss: 1.1834 - accuracy: 0.6413\n",
            "Epoch 37/65\n",
            "46905/46905 [==============================] - 32s 690us/step - loss: 1.1601 - accuracy: 0.6463\n",
            "Epoch 38/65\n",
            "46905/46905 [==============================] - 33s 695us/step - loss: 1.1585 - accuracy: 0.6505\n",
            "Epoch 39/65\n",
            "46905/46905 [==============================] - 33s 700us/step - loss: 1.1519 - accuracy: 0.6530\n",
            "Epoch 40/65\n",
            "46905/46905 [==============================] - 33s 701us/step - loss: 1.1275 - accuracy: 0.6603\n",
            "Epoch 41/65\n",
            "46905/46905 [==============================] - 33s 701us/step - loss: 1.1250 - accuracy: 0.6598\n",
            "Epoch 42/65\n",
            "46905/46905 [==============================] - 33s 703us/step - loss: 1.1043 - accuracy: 0.6654\n",
            "Epoch 43/65\n",
            "46905/46905 [==============================] - 33s 709us/step - loss: 1.1066 - accuracy: 0.6641\n",
            "Epoch 44/65\n",
            "46905/46905 [==============================] - 33s 703us/step - loss: 1.0924 - accuracy: 0.6706\n",
            "Epoch 45/65\n",
            "46905/46905 [==============================] - 32s 691us/step - loss: 1.0780 - accuracy: 0.6713\n",
            "Epoch 46/65\n",
            "46905/46905 [==============================] - 33s 694us/step - loss: 1.0702 - accuracy: 0.6764\n",
            "Epoch 47/65\n",
            "46905/46905 [==============================] - 32s 680us/step - loss: 1.0637 - accuracy: 0.6799\n",
            "Epoch 48/65\n",
            "46905/46905 [==============================] - 33s 696us/step - loss: 1.0588 - accuracy: 0.6796\n",
            "Epoch 49/65\n",
            "46905/46905 [==============================] - 33s 698us/step - loss: 1.0433 - accuracy: 0.6859\n",
            "Epoch 50/65\n",
            "46905/46905 [==============================] - 32s 691us/step - loss: 1.0411 - accuracy: 0.6853\n",
            "Epoch 51/65\n",
            "46905/46905 [==============================] - 32s 693us/step - loss: 1.0267 - accuracy: 0.6899\n",
            "Epoch 52/65\n",
            "46905/46905 [==============================] - 32s 692us/step - loss: 1.0293 - accuracy: 0.6885\n",
            "Epoch 53/65\n",
            "46905/46905 [==============================] - 33s 697us/step - loss: 1.0127 - accuracy: 0.6924\n",
            "Epoch 54/65\n",
            "46905/46905 [==============================] - 33s 697us/step - loss: 1.0106 - accuracy: 0.6937\n",
            "Epoch 55/65\n",
            "46905/46905 [==============================] - 33s 699us/step - loss: 1.0019 - accuracy: 0.6970\n",
            "Epoch 56/65\n",
            "46905/46905 [==============================] - 33s 702us/step - loss: 0.9858 - accuracy: 0.7001\n",
            "Epoch 57/65\n",
            "46905/46905 [==============================] - 33s 696us/step - loss: 0.9844 - accuracy: 0.7008\n",
            "Epoch 58/65\n",
            "46905/46905 [==============================] - 33s 699us/step - loss: 0.9920 - accuracy: 0.6981\n",
            "Epoch 59/65\n",
            "46905/46905 [==============================] - 33s 693us/step - loss: 0.9689 - accuracy: 0.7049\n",
            "Epoch 60/65\n",
            "46905/46905 [==============================] - 33s 694us/step - loss: 0.9731 - accuracy: 0.7038\n",
            "Epoch 61/65\n",
            "46905/46905 [==============================] - 33s 713us/step - loss: 0.9645 - accuracy: 0.7080\n",
            "Epoch 62/65\n",
            "46905/46905 [==============================] - 34s 721us/step - loss: 0.9574 - accuracy: 0.7096\n",
            "Epoch 63/65\n",
            "46905/46905 [==============================] - 33s 695us/step - loss: 0.9524 - accuracy: 0.7117\n",
            "Epoch 64/65\n",
            "46905/46905 [==============================] - 33s 701us/step - loss: 0.9507 - accuracy: 0.7138\n",
            "Epoch 65/65\n",
            "46905/46905 [==============================] - 33s 698us/step - loss: 0.9436 - accuracy: 0.7143\n",
            "[0.6504284438955171, 0.8150421977043152]\n",
            "TRAIN: 46905 TEST: 5212 Epoch 1/65\n",
            "46905/46905 [==============================] - 33s 699us/step - loss: 3.3950 - accuracy: 0.0390\n",
            "Epoch 2/65\n",
            "46905/46905 [==============================] - 33s 694us/step - loss: 3.3863 - accuracy: 0.0446\n",
            "Epoch 3/65\n",
            "46905/46905 [==============================] - 33s 705us/step - loss: 3.3673 - accuracy: 0.0513\n",
            "Epoch 4/65\n",
            "46905/46905 [==============================] - 32s 690us/step - loss: 3.3002 - accuracy: 0.0747\n",
            "Epoch 5/65\n",
            "46905/46905 [==============================] - 33s 705us/step - loss: 3.1009 - accuracy: 0.1184\n",
            "Epoch 6/65\n",
            "46905/46905 [==============================] - 34s 725us/step - loss: 2.8493 - accuracy: 0.1688\n",
            "Epoch 7/65\n",
            "46905/46905 [==============================] - 33s 700us/step - loss: 2.6588 - accuracy: 0.2153\n",
            "Epoch 8/65\n",
            "46905/46905 [==============================] - 33s 700us/step - loss: 2.5203 - accuracy: 0.2550\n",
            "Epoch 9/65\n",
            "46905/46905 [==============================] - 33s 694us/step - loss: 2.3965 - accuracy: 0.2916\n",
            "Epoch 10/65\n",
            "46905/46905 [==============================] - 32s 680us/step - loss: 2.2959 - accuracy: 0.3188\n",
            "Epoch 11/65\n",
            "46905/46905 [==============================] - 33s 699us/step - loss: 2.1974 - accuracy: 0.3480\n",
            "Epoch 12/65\n",
            "46905/46905 [==============================] - 33s 698us/step - loss: 2.1137 - accuracy: 0.3728\n",
            "Epoch 13/65\n",
            "46905/46905 [==============================] - 33s 703us/step - loss: 2.0273 - accuracy: 0.3953\n",
            "Epoch 14/65\n",
            "46905/46905 [==============================] - 34s 720us/step - loss: 1.9497 - accuracy: 0.4166\n",
            "Epoch 15/65\n",
            "46905/46905 [==============================] - 33s 703us/step - loss: 1.8789 - accuracy: 0.4364\n",
            "Epoch 16/65\n",
            "46905/46905 [==============================] - 34s 720us/step - loss: 1.8133 - accuracy: 0.4554\n",
            "Epoch 17/65\n",
            "46905/46905 [==============================] - 33s 694us/step - loss: 1.7476 - accuracy: 0.4717\n",
            "Epoch 18/65\n",
            "46905/46905 [==============================] - 33s 700us/step - loss: 1.6890 - accuracy: 0.4893\n",
            "Epoch 19/65\n",
            "46905/46905 [==============================] - 33s 701us/step - loss: 1.6385 - accuracy: 0.5056\n",
            "Epoch 20/65\n",
            "46905/46905 [==============================] - 33s 703us/step - loss: 1.5834 - accuracy: 0.5226\n",
            "Epoch 21/65\n",
            "46905/46905 [==============================] - 32s 692us/step - loss: 1.5452 - accuracy: 0.5321\n",
            "Epoch 22/65\n",
            "46905/46905 [==============================] - 33s 693us/step - loss: 1.4976 - accuracy: 0.5454\n",
            "Epoch 23/65\n",
            "46905/46905 [==============================] - 33s 696us/step - loss: 1.4676 - accuracy: 0.5554\n",
            "Epoch 24/65\n",
            "46905/46905 [==============================] - 33s 702us/step - loss: 1.4304 - accuracy: 0.5664\n",
            "Epoch 25/65\n",
            "46905/46905 [==============================] - 33s 700us/step - loss: 1.4001 - accuracy: 0.5771\n",
            "Epoch 26/65\n",
            "46905/46905 [==============================] - 33s 697us/step - loss: 1.3767 - accuracy: 0.5826\n",
            "Epoch 27/65\n",
            "46905/46905 [==============================] - 33s 705us/step - loss: 1.3481 - accuracy: 0.5930\n",
            "Epoch 28/65\n",
            "46905/46905 [==============================] - 33s 703us/step - loss: 1.3242 - accuracy: 0.5981\n",
            "Epoch 29/65\n",
            "46905/46905 [==============================] - 33s 698us/step - loss: 1.3073 - accuracy: 0.6047\n",
            "Epoch 30/65\n",
            "46905/46905 [==============================] - 33s 700us/step - loss: 1.2796 - accuracy: 0.6129\n",
            "Epoch 31/65\n",
            "46905/46905 [==============================] - 32s 688us/step - loss: 1.2672 - accuracy: 0.6164\n",
            "Epoch 32/65\n",
            "46905/46905 [==============================] - 32s 693us/step - loss: 1.2424 - accuracy: 0.6247\n",
            "Epoch 33/65\n",
            "46905/46905 [==============================] - 33s 703us/step - loss: 1.2295 - accuracy: 0.6289\n",
            "Epoch 34/65\n",
            "46905/46905 [==============================] - 33s 695us/step - loss: 1.2067 - accuracy: 0.6359\n",
            "Epoch 35/65\n",
            "46905/46905 [==============================] - 33s 702us/step - loss: 1.1903 - accuracy: 0.6369\n",
            "Epoch 36/65\n",
            "46905/46905 [==============================] - 33s 700us/step - loss: 1.1709 - accuracy: 0.6461\n",
            "Epoch 37/65\n",
            "46905/46905 [==============================] - 32s 688us/step - loss: 1.1571 - accuracy: 0.6512\n",
            "Epoch 38/65\n",
            "46905/46905 [==============================] - 33s 702us/step - loss: 1.1386 - accuracy: 0.6556\n",
            "Epoch 39/65\n",
            "46905/46905 [==============================] - 33s 707us/step - loss: 1.1361 - accuracy: 0.6539\n",
            "Epoch 40/65\n",
            "46905/46905 [==============================] - 33s 700us/step - loss: 1.1177 - accuracy: 0.6619\n",
            "Epoch 41/65\n",
            "46905/46905 [==============================] - 33s 698us/step - loss: 1.1025 - accuracy: 0.6672\n",
            "Epoch 42/65\n",
            "46905/46905 [==============================] - 33s 697us/step - loss: 1.0941 - accuracy: 0.6706\n",
            "Epoch 43/65\n",
            "46905/46905 [==============================] - 32s 680us/step - loss: 1.0830 - accuracy: 0.6710\n",
            "Epoch 44/65\n",
            "46905/46905 [==============================] - 34s 716us/step - loss: 1.0739 - accuracy: 0.6754\n",
            "Epoch 45/65\n",
            "46905/46905 [==============================] - 34s 716us/step - loss: 1.0543 - accuracy: 0.6812\n",
            "Epoch 46/65\n",
            "46905/46905 [==============================] - 33s 696us/step - loss: 1.0451 - accuracy: 0.6818\n",
            "Epoch 47/65\n",
            "46905/46905 [==============================] - 33s 701us/step - loss: 1.0492 - accuracy: 0.6809\n",
            "Epoch 48/65\n",
            "46905/46905 [==============================] - 33s 693us/step - loss: 1.0331 - accuracy: 0.6891\n",
            "Epoch 49/65\n",
            "46905/46905 [==============================] - 33s 705us/step - loss: 1.0210 - accuracy: 0.6911\n",
            "Epoch 50/65\n",
            "46905/46905 [==============================] - 33s 698us/step - loss: 1.0217 - accuracy: 0.6927\n",
            "Epoch 51/65\n",
            "46905/46905 [==============================] - 33s 709us/step - loss: 1.0064 - accuracy: 0.6939\n",
            "Epoch 52/65\n",
            "46905/46905 [==============================] - 33s 710us/step - loss: 1.0012 - accuracy: 0.6971\n",
            "Epoch 53/65\n",
            "46905/46905 [==============================] - 33s 703us/step - loss: 0.9903 - accuracy: 0.6995\n",
            "Epoch 54/65\n",
            "46905/46905 [==============================] - 33s 701us/step - loss: 0.9819 - accuracy: 0.7012\n",
            "Epoch 55/65\n",
            "46905/46905 [==============================] - 32s 691us/step - loss: 0.9716 - accuracy: 0.7066\n",
            "Epoch 56/65\n",
            "46905/46905 [==============================] - 32s 689us/step - loss: 0.9724 - accuracy: 0.7045\n",
            "Epoch 57/65\n",
            "46905/46905 [==============================] - 33s 697us/step - loss: 0.9612 - accuracy: 0.7077\n",
            "Epoch 58/65\n",
            "46905/46905 [==============================] - 33s 700us/step - loss: 0.9553 - accuracy: 0.7116\n",
            "Epoch 59/65\n",
            "46905/46905 [==============================] - 33s 695us/step - loss: 0.9505 - accuracy: 0.7098\n",
            "Epoch 60/65\n",
            "46905/46905 [==============================] - 32s 692us/step - loss: 0.9444 - accuracy: 0.7147\n",
            "Epoch 61/65\n",
            "46905/46905 [==============================] - 33s 694us/step - loss: 0.9343 - accuracy: 0.7171\n",
            "Epoch 62/65\n",
            "46905/46905 [==============================] - 33s 710us/step - loss: 0.9257 - accuracy: 0.7212\n",
            "Epoch 63/65\n",
            "46905/46905 [==============================] - 33s 710us/step - loss: 0.9250 - accuracy: 0.7202\n",
            "Epoch 64/65\n",
            "46905/46905 [==============================] - 33s 705us/step - loss: 0.9285 - accuracy: 0.7228\n",
            "Epoch 65/65\n",
            "46905/46905 [==============================] - 33s 698us/step - loss: 0.9184 - accuracy: 0.7229\n",
            "[0.5788970370751935, 0.839984655380249]\n",
            "TRAIN: 46905 TEST: 5212 Epoch 1/65\n",
            "46905/46905 [==============================] - 34s 718us/step - loss: 3.3959 - accuracy: 0.0387\n",
            "Epoch 2/65\n",
            "46905/46905 [==============================] - 33s 712us/step - loss: 3.3888 - accuracy: 0.0434\n",
            "Epoch 3/65\n",
            "46905/46905 [==============================] - 33s 713us/step - loss: 3.3744 - accuracy: 0.0495\n",
            "Epoch 4/65\n",
            "46905/46905 [==============================] - 34s 719us/step - loss: 3.3083 - accuracy: 0.0741\n",
            "Epoch 5/65\n",
            "46905/46905 [==============================] - 34s 715us/step - loss: 3.1274 - accuracy: 0.1080\n",
            "Epoch 6/65\n",
            "46905/46905 [==============================] - 34s 720us/step - loss: 2.9102 - accuracy: 0.1522\n",
            "Epoch 7/65\n",
            "46905/46905 [==============================] - 34s 727us/step - loss: 2.7089 - accuracy: 0.2014\n",
            "Epoch 8/65\n",
            "46905/46905 [==============================] - 33s 712us/step - loss: 2.5656 - accuracy: 0.2398\n",
            "Epoch 9/65\n",
            "46905/46905 [==============================] - 34s 715us/step - loss: 2.4485 - accuracy: 0.2731\n",
            "Epoch 10/65\n",
            "46905/46905 [==============================] - 33s 709us/step - loss: 2.3415 - accuracy: 0.3041\n",
            "Epoch 11/65\n",
            "46905/46905 [==============================] - 33s 711us/step - loss: 2.2661 - accuracy: 0.3250\n",
            "Epoch 12/65\n",
            "46905/46905 [==============================] - 33s 710us/step - loss: 2.1851 - accuracy: 0.3485\n",
            "Epoch 13/65\n",
            "46905/46905 [==============================] - 33s 712us/step - loss: 2.0962 - accuracy: 0.3735\n",
            "Epoch 14/65\n",
            "46905/46905 [==============================] - 34s 723us/step - loss: 2.0183 - accuracy: 0.3951\n",
            "Epoch 15/65\n",
            "46905/46905 [==============================] - 33s 712us/step - loss: 1.9433 - accuracy: 0.4182\n",
            "Epoch 16/65\n",
            "46905/46905 [==============================] - 34s 715us/step - loss: 1.8804 - accuracy: 0.4353\n",
            "Epoch 17/65\n",
            "46905/46905 [==============================] - 33s 713us/step - loss: 1.8173 - accuracy: 0.4539\n",
            "Epoch 18/65\n",
            "46905/46905 [==============================] - 33s 707us/step - loss: 1.7529 - accuracy: 0.4701\n",
            "Epoch 19/65\n",
            "46905/46905 [==============================] - 33s 704us/step - loss: 1.6974 - accuracy: 0.4841\n",
            "Epoch 20/65\n",
            "46905/46905 [==============================] - 33s 711us/step - loss: 1.6506 - accuracy: 0.5016\n",
            "Epoch 21/65\n",
            "46905/46905 [==============================] - 33s 710us/step - loss: 1.6045 - accuracy: 0.5195\n",
            "Epoch 22/65\n",
            "46905/46905 [==============================] - 34s 723us/step - loss: 1.5568 - accuracy: 0.5283\n",
            "Epoch 23/65\n",
            "46905/46905 [==============================] - 34s 723us/step - loss: 1.5219 - accuracy: 0.5382\n",
            "Epoch 24/65\n",
            "46905/46905 [==============================] - 33s 714us/step - loss: 1.4812 - accuracy: 0.5497\n",
            "Epoch 25/65\n",
            "46905/46905 [==============================] - 33s 713us/step - loss: 1.4471 - accuracy: 0.5615\n",
            "Epoch 26/65\n",
            "46905/46905 [==============================] - 34s 721us/step - loss: 1.4138 - accuracy: 0.5703\n",
            "Epoch 27/65\n",
            "46905/46905 [==============================] - 33s 694us/step - loss: 1.3815 - accuracy: 0.5818\n",
            "Epoch 28/65\n",
            "46905/46905 [==============================] - 33s 706us/step - loss: 1.3574 - accuracy: 0.5882\n",
            "Epoch 29/65\n",
            "46905/46905 [==============================] - 33s 701us/step - loss: 1.3326 - accuracy: 0.5974\n",
            "Epoch 30/65\n",
            "46905/46905 [==============================] - 33s 694us/step - loss: 1.3025 - accuracy: 0.6054\n",
            "Epoch 31/65\n",
            "46905/46905 [==============================] - 33s 701us/step - loss: 1.2825 - accuracy: 0.6101\n",
            "Epoch 32/65\n",
            "46905/46905 [==============================] - 33s 705us/step - loss: 1.2591 - accuracy: 0.6200\n",
            "Epoch 33/65\n",
            "46905/46905 [==============================] - 33s 712us/step - loss: 1.2457 - accuracy: 0.6222\n",
            "Epoch 34/65\n",
            "46905/46905 [==============================] - 33s 707us/step - loss: 1.2237 - accuracy: 0.6298\n",
            "Epoch 35/65\n",
            "46905/46905 [==============================] - 33s 711us/step - loss: 1.2033 - accuracy: 0.6345\n",
            "Epoch 36/65\n",
            "46905/46905 [==============================] - 33s 701us/step - loss: 1.1832 - accuracy: 0.6402\n",
            "Epoch 37/65\n",
            "46905/46905 [==============================] - 32s 692us/step - loss: 1.1680 - accuracy: 0.6459\n",
            "Epoch 38/65\n",
            "46905/46905 [==============================] - 33s 707us/step - loss: 1.1548 - accuracy: 0.6504\n",
            "Epoch 39/65\n",
            "46905/46905 [==============================] - 33s 702us/step - loss: 1.1414 - accuracy: 0.6560\n",
            "Epoch 40/65\n",
            "46905/46905 [==============================] - 33s 706us/step - loss: 1.1269 - accuracy: 0.6591\n",
            "Epoch 41/65\n",
            "46905/46905 [==============================] - 34s 715us/step - loss: 1.1199 - accuracy: 0.6584\n",
            "Epoch 42/65\n",
            "46905/46905 [==============================] - 33s 704us/step - loss: 1.0983 - accuracy: 0.6668\n",
            "Epoch 43/65\n",
            "46905/46905 [==============================] - 33s 704us/step - loss: 1.0926 - accuracy: 0.6675\n",
            "Epoch 44/65\n",
            "46905/46905 [==============================] - 33s 707us/step - loss: 1.0811 - accuracy: 0.6710\n",
            "Epoch 45/65\n",
            "46905/46905 [==============================] - 33s 706us/step - loss: 1.0659 - accuracy: 0.6762\n",
            "Epoch 46/65\n",
            "46905/46905 [==============================] - 33s 708us/step - loss: 1.0617 - accuracy: 0.6799\n",
            "Epoch 47/65\n",
            "46905/46905 [==============================] - 33s 701us/step - loss: 1.0541 - accuracy: 0.6804\n",
            "Epoch 48/65\n",
            "46905/46905 [==============================] - 33s 704us/step - loss: 1.0387 - accuracy: 0.6832\n",
            "Epoch 49/65\n",
            "46905/46905 [==============================] - 33s 696us/step - loss: 1.0361 - accuracy: 0.6883\n",
            "Epoch 50/65\n",
            "46905/46905 [==============================] - 33s 704us/step - loss: 1.0321 - accuracy: 0.6854\n",
            "Epoch 51/65\n",
            "46905/46905 [==============================] - 33s 698us/step - loss: 1.0173 - accuracy: 0.6915\n",
            "Epoch 52/65\n",
            "46905/46905 [==============================] - 33s 706us/step - loss: 1.0126 - accuracy: 0.6944\n",
            "Epoch 53/65\n",
            "46905/46905 [==============================] - 33s 705us/step - loss: 1.0083 - accuracy: 0.6958\n",
            "Epoch 54/65\n",
            "46905/46905 [==============================] - 34s 721us/step - loss: 0.9960 - accuracy: 0.6985\n",
            "Epoch 55/65\n",
            "46905/46905 [==============================] - 33s 711us/step - loss: 0.9900 - accuracy: 0.7013\n",
            "Epoch 56/65\n",
            "46905/46905 [==============================] - 33s 701us/step - loss: 0.9770 - accuracy: 0.7039\n",
            "Epoch 57/65\n",
            "46905/46905 [==============================] - 33s 705us/step - loss: 0.9809 - accuracy: 0.7031\n",
            "Epoch 58/65\n",
            "46905/46905 [==============================] - 33s 702us/step - loss: 0.9664 - accuracy: 0.7068\n",
            "Epoch 59/65\n",
            "46905/46905 [==============================] - 33s 705us/step - loss: 0.9642 - accuracy: 0.7047\n",
            "Epoch 60/65\n",
            "46905/46905 [==============================] - 33s 708us/step - loss: 0.9511 - accuracy: 0.7091\n",
            "Epoch 61/65\n",
            "46905/46905 [==============================] - 33s 697us/step - loss: 0.9510 - accuracy: 0.7111\n",
            "Epoch 62/65\n",
            "46905/46905 [==============================] - 33s 700us/step - loss: 0.9469 - accuracy: 0.7128\n",
            "Epoch 63/65\n",
            "46905/46905 [==============================] - 33s 712us/step - loss: 0.9427 - accuracy: 0.7147\n",
            "Epoch 64/65\n",
            "46905/46905 [==============================] - 32s 692us/step - loss: 0.9372 - accuracy: 0.7156\n",
            "Epoch 65/65\n",
            "46905/46905 [==============================] - 33s 705us/step - loss: 0.9285 - accuracy: 0.7169\n",
            "[0.6253676089706187, 0.8148503303527832]\n",
            "TRAIN: 46905 TEST: 5212 Epoch 1/65\n",
            "46905/46905 [==============================] - 33s 713us/step - loss: 3.3960 - accuracy: 0.0396\n",
            "Epoch 2/65\n",
            "46905/46905 [==============================] - 33s 709us/step - loss: 3.3853 - accuracy: 0.0480\n",
            "Epoch 3/65\n",
            "46905/46905 [==============================] - 33s 709us/step - loss: 3.3633 - accuracy: 0.0553\n",
            "Epoch 4/65\n",
            "46905/46905 [==============================] - 33s 704us/step - loss: 3.2897 - accuracy: 0.0802\n",
            "Epoch 5/65\n",
            "46905/46905 [==============================] - 33s 697us/step - loss: 3.1012 - accuracy: 0.1189\n",
            "Epoch 6/65\n",
            "46905/46905 [==============================] - 33s 708us/step - loss: 2.8574 - accuracy: 0.1694\n",
            "Epoch 7/65\n",
            "46905/46905 [==============================] - 34s 727us/step - loss: 2.6729 - accuracy: 0.2126\n",
            "Epoch 8/65\n",
            "46905/46905 [==============================] - 33s 697us/step - loss: 2.5299 - accuracy: 0.2543\n",
            "Epoch 9/65\n",
            "46905/46905 [==============================] - 33s 713us/step - loss: 2.4076 - accuracy: 0.2900\n",
            "Epoch 10/65\n",
            "46905/46905 [==============================] - 33s 705us/step - loss: 2.3055 - accuracy: 0.3171\n",
            "Epoch 11/65\n",
            "46905/46905 [==============================] - 33s 710us/step - loss: 2.2123 - accuracy: 0.3427\n",
            "Epoch 12/65\n",
            "46905/46905 [==============================] - 34s 725us/step - loss: 2.1174 - accuracy: 0.3701\n",
            "Epoch 13/65\n",
            "46905/46905 [==============================] - 34s 722us/step - loss: 2.0353 - accuracy: 0.3947\n",
            "Epoch 14/65\n",
            "46905/46905 [==============================] - 34s 715us/step - loss: 1.9573 - accuracy: 0.4146\n",
            "Epoch 15/65\n",
            "46905/46905 [==============================] - 33s 706us/step - loss: 1.8821 - accuracy: 0.4363\n",
            "Epoch 16/65\n",
            "46905/46905 [==============================] - 34s 715us/step - loss: 1.8207 - accuracy: 0.4517\n",
            "Epoch 17/65\n",
            "46905/46905 [==============================] - 34s 722us/step - loss: 1.7558 - accuracy: 0.4730\n",
            "Epoch 18/65\n",
            "46905/46905 [==============================] - 33s 702us/step - loss: 1.6925 - accuracy: 0.4899\n",
            "Epoch 19/65\n",
            "46905/46905 [==============================] - 33s 712us/step - loss: 1.6429 - accuracy: 0.5042\n",
            "Epoch 20/65\n",
            "46905/46905 [==============================] - 33s 707us/step - loss: 1.5757 - accuracy: 0.5229\n",
            "Epoch 21/65\n",
            "46905/46905 [==============================] - 34s 716us/step - loss: 1.5404 - accuracy: 0.5383\n",
            "Epoch 22/65\n",
            "46905/46905 [==============================] - 33s 708us/step - loss: 1.4940 - accuracy: 0.5470\n",
            "Epoch 23/65\n",
            "46905/46905 [==============================] - 33s 703us/step - loss: 1.4728 - accuracy: 0.5540\n",
            "Epoch 24/65\n",
            "46905/46905 [==============================] - 33s 710us/step - loss: 1.4347 - accuracy: 0.5638\n",
            "Epoch 25/65\n",
            "46905/46905 [==============================] - 33s 703us/step - loss: 1.3922 - accuracy: 0.5787\n",
            "Epoch 26/65\n",
            "46905/46905 [==============================] - 34s 714us/step - loss: 1.3644 - accuracy: 0.5867\n",
            "Epoch 27/65\n",
            "46905/46905 [==============================] - 33s 696us/step - loss: 1.3417 - accuracy: 0.5916\n",
            "Epoch 28/65\n",
            "46905/46905 [==============================] - 33s 700us/step - loss: 1.3204 - accuracy: 0.6010\n",
            "Epoch 29/65\n",
            "46905/46905 [==============================] - 33s 694us/step - loss: 1.2932 - accuracy: 0.6072\n",
            "Epoch 30/65\n",
            "46905/46905 [==============================] - 33s 705us/step - loss: 1.2763 - accuracy: 0.6121\n",
            "Epoch 31/65\n",
            "46905/46905 [==============================] - 34s 721us/step - loss: 1.2520 - accuracy: 0.6205\n",
            "Epoch 32/65\n",
            "46905/46905 [==============================] - 33s 704us/step - loss: 1.2350 - accuracy: 0.6272\n",
            "Epoch 33/65\n",
            "46905/46905 [==============================] - 33s 714us/step - loss: 1.2219 - accuracy: 0.6338\n",
            "Epoch 34/65\n",
            "46905/46905 [==============================] - 33s 700us/step - loss: 1.2022 - accuracy: 0.6358\n",
            "Epoch 35/65\n",
            "46905/46905 [==============================] - 34s 720us/step - loss: 1.1874 - accuracy: 0.6401\n",
            "Epoch 36/65\n",
            "46905/46905 [==============================] - 34s 714us/step - loss: 1.1758 - accuracy: 0.6453\n",
            "Epoch 37/65\n",
            "46905/46905 [==============================] - 33s 700us/step - loss: 1.1614 - accuracy: 0.6488\n",
            "Epoch 38/65\n",
            "46905/46905 [==============================] - 33s 708us/step - loss: 1.1442 - accuracy: 0.6523\n",
            "Epoch 39/65\n",
            "46905/46905 [==============================] - 33s 708us/step - loss: 1.1276 - accuracy: 0.6599\n",
            "Epoch 40/65\n",
            "46905/46905 [==============================] - 33s 697us/step - loss: 1.1220 - accuracy: 0.6614\n",
            "Epoch 41/65\n",
            "46905/46905 [==============================] - 33s 699us/step - loss: 1.1118 - accuracy: 0.6628\n",
            "Epoch 42/65\n",
            "46905/46905 [==============================] - 33s 703us/step - loss: 1.0998 - accuracy: 0.6691\n",
            "Epoch 43/65\n",
            "46905/46905 [==============================] - 33s 708us/step - loss: 1.0859 - accuracy: 0.6727\n",
            "Epoch 44/65\n",
            "46905/46905 [==============================] - 33s 695us/step - loss: 1.0804 - accuracy: 0.6746\n",
            "Epoch 45/65\n",
            "46905/46905 [==============================] - 34s 726us/step - loss: 1.0699 - accuracy: 0.6783\n",
            "Epoch 46/65\n",
            "46905/46905 [==============================] - 33s 704us/step - loss: 1.0549 - accuracy: 0.6822\n",
            "Epoch 47/65\n",
            "46905/46905 [==============================] - 33s 714us/step - loss: 1.0530 - accuracy: 0.6801\n",
            "Epoch 48/65\n",
            "46905/46905 [==============================] - 33s 704us/step - loss: 1.0341 - accuracy: 0.6878\n",
            "Epoch 49/65\n",
            "46905/46905 [==============================] - 33s 704us/step - loss: 1.0392 - accuracy: 0.6878\n",
            "Epoch 50/65\n",
            "46905/46905 [==============================] - 33s 711us/step - loss: 1.0207 - accuracy: 0.6913\n",
            "Epoch 51/65\n",
            "46905/46905 [==============================] - 33s 697us/step - loss: 1.0173 - accuracy: 0.6910\n",
            "Epoch 52/65\n",
            "46905/46905 [==============================] - 33s 704us/step - loss: 1.0088 - accuracy: 0.6952\n",
            "Epoch 53/65\n",
            "46905/46905 [==============================] - 33s 702us/step - loss: 0.9927 - accuracy: 0.6984\n",
            "Epoch 54/65\n",
            "46905/46905 [==============================] - 33s 713us/step - loss: 0.9944 - accuracy: 0.7025\n",
            "Epoch 55/65\n",
            "46905/46905 [==============================] - 33s 702us/step - loss: 0.9858 - accuracy: 0.7035\n",
            "Epoch 56/65\n",
            "46905/46905 [==============================] - 33s 708us/step - loss: 0.9862 - accuracy: 0.7021\n",
            "Epoch 57/65\n",
            "46905/46905 [==============================] - 34s 718us/step - loss: 0.9763 - accuracy: 0.7026\n",
            "Epoch 58/65\n",
            "46905/46905 [==============================] - 33s 707us/step - loss: 0.9723 - accuracy: 0.7055\n",
            "Epoch 59/65\n",
            "46905/46905 [==============================] - 34s 726us/step - loss: 0.9660 - accuracy: 0.7082\n",
            "Epoch 60/65\n",
            "46905/46905 [==============================] - 32s 691us/step - loss: 0.9494 - accuracy: 0.7128\n",
            "Epoch 61/65\n",
            "46905/46905 [==============================] - 33s 701us/step - loss: 0.9495 - accuracy: 0.7136\n",
            "Epoch 62/65\n",
            "46905/46905 [==============================] - 33s 704us/step - loss: 0.9417 - accuracy: 0.7165\n",
            "Epoch 63/65\n",
            "46905/46905 [==============================] - 33s 708us/step - loss: 0.9422 - accuracy: 0.7155\n",
            "Epoch 64/65\n",
            "46905/46905 [==============================] - 34s 720us/step - loss: 0.9354 - accuracy: 0.7170\n",
            "Epoch 65/65\n",
            "46905/46905 [==============================] - 33s 713us/step - loss: 0.9317 - accuracy: 0.7194\n",
            "[0.5648825041898287, 0.839984655380249]\n",
            "TRAIN: 46905 TEST: 5212 Epoch 1/65\n",
            "46905/46905 [==============================] - 34s 728us/step - loss: 3.3954 - accuracy: 0.0394\n",
            "Epoch 2/65\n",
            "46905/46905 [==============================] - 34s 715us/step - loss: 3.3858 - accuracy: 0.0449\n",
            "Epoch 3/65\n",
            "46905/46905 [==============================] - 33s 702us/step - loss: 3.3623 - accuracy: 0.0567\n",
            "Epoch 4/65\n",
            "46905/46905 [==============================] - 33s 708us/step - loss: 3.2558 - accuracy: 0.0843\n",
            "Epoch 5/65\n",
            "46905/46905 [==============================] - 33s 699us/step - loss: 3.0280 - accuracy: 0.1294\n",
            "Epoch 6/65\n",
            "46905/46905 [==============================] - 33s 709us/step - loss: 2.8149 - accuracy: 0.1753\n",
            "Epoch 7/65\n",
            "46905/46905 [==============================] - 34s 720us/step - loss: 2.6577 - accuracy: 0.2138\n",
            "Epoch 8/65\n",
            "46905/46905 [==============================] - 34s 719us/step - loss: 2.5394 - accuracy: 0.2477\n",
            "Epoch 9/65\n",
            "46905/46905 [==============================] - 33s 709us/step - loss: 2.4482 - accuracy: 0.2768\n",
            "Epoch 10/65\n",
            "46905/46905 [==============================] - 33s 709us/step - loss: 2.3573 - accuracy: 0.2999\n",
            "Epoch 11/65\n",
            "46905/46905 [==============================] - 33s 708us/step - loss: 2.2864 - accuracy: 0.3207\n",
            "Epoch 12/65\n",
            "46905/46905 [==============================] - 34s 729us/step - loss: 2.2067 - accuracy: 0.3419\n",
            "Epoch 13/65\n",
            "46905/46905 [==============================] - 33s 708us/step - loss: 2.1245 - accuracy: 0.3649\n",
            "Epoch 14/65\n",
            "46905/46905 [==============================] - 33s 709us/step - loss: 2.0581 - accuracy: 0.3850\n",
            "Epoch 15/65\n",
            "46905/46905 [==============================] - 33s 712us/step - loss: 1.9919 - accuracy: 0.4054\n",
            "Epoch 16/65\n",
            "46905/46905 [==============================] - 34s 722us/step - loss: 1.9209 - accuracy: 0.4240\n",
            "Epoch 17/65\n",
            "46905/46905 [==============================] - 34s 716us/step - loss: 1.8528 - accuracy: 0.4420\n",
            "Epoch 18/65\n",
            "46905/46905 [==============================] - 33s 696us/step - loss: 1.7901 - accuracy: 0.4626\n",
            "Epoch 19/65\n",
            "46905/46905 [==============================] - 33s 713us/step - loss: 1.7299 - accuracy: 0.4775\n",
            "Epoch 20/65\n",
            "46905/46905 [==============================] - 33s 703us/step - loss: 1.6738 - accuracy: 0.4934\n",
            "Epoch 21/65\n",
            "46905/46905 [==============================] - 34s 720us/step - loss: 1.6192 - accuracy: 0.5122\n",
            "Epoch 22/65\n",
            "46905/46905 [==============================] - 34s 715us/step - loss: 1.5718 - accuracy: 0.5233\n",
            "Epoch 23/65\n",
            "46905/46905 [==============================] - 33s 703us/step - loss: 1.5184 - accuracy: 0.5381\n",
            "Epoch 24/65\n",
            "46905/46905 [==============================] - 33s 714us/step - loss: 1.4862 - accuracy: 0.5513\n",
            "Epoch 25/65\n",
            "46905/46905 [==============================] - 33s 702us/step - loss: 1.4578 - accuracy: 0.5607\n",
            "Epoch 26/65\n",
            "46905/46905 [==============================] - 34s 718us/step - loss: 1.4140 - accuracy: 0.5728\n",
            "Epoch 27/65\n",
            "46905/46905 [==============================] - 33s 702us/step - loss: 1.3804 - accuracy: 0.5807\n",
            "Epoch 28/65\n",
            "46905/46905 [==============================] - 33s 702us/step - loss: 1.3707 - accuracy: 0.5844\n",
            "Epoch 29/65\n",
            "46905/46905 [==============================] - 33s 713us/step - loss: 1.3343 - accuracy: 0.5941\n",
            "Epoch 30/65\n",
            "46905/46905 [==============================] - 34s 715us/step - loss: 1.3137 - accuracy: 0.6008\n",
            "Epoch 31/65\n",
            "46905/46905 [==============================] - 34s 715us/step - loss: 1.2826 - accuracy: 0.6104\n",
            "Epoch 32/65\n",
            "46905/46905 [==============================] - 33s 700us/step - loss: 1.2603 - accuracy: 0.6173\n",
            "Epoch 33/65\n",
            "46905/46905 [==============================] - 33s 708us/step - loss: 1.2472 - accuracy: 0.6215\n",
            "Epoch 34/65\n",
            "46905/46905 [==============================] - 33s 698us/step - loss: 1.2270 - accuracy: 0.6305\n",
            "Epoch 35/65\n",
            "46905/46905 [==============================] - 33s 711us/step - loss: 1.2097 - accuracy: 0.6338\n",
            "Epoch 36/65\n",
            "46905/46905 [==============================] - 33s 698us/step - loss: 1.1920 - accuracy: 0.6399\n",
            "Epoch 37/65\n",
            "46905/46905 [==============================] - 33s 711us/step - loss: 1.1788 - accuracy: 0.6434\n",
            "Epoch 38/65\n",
            "46905/46905 [==============================] - 33s 711us/step - loss: 1.1559 - accuracy: 0.6479\n",
            "Epoch 39/65\n",
            "46905/46905 [==============================] - 33s 703us/step - loss: 1.1555 - accuracy: 0.6501\n",
            "Epoch 40/65\n",
            "46905/46905 [==============================] - 33s 707us/step - loss: 1.1353 - accuracy: 0.6563\n",
            "Epoch 41/65\n",
            "46905/46905 [==============================] - 33s 704us/step - loss: 1.1171 - accuracy: 0.6622\n",
            "Epoch 42/65\n",
            "46905/46905 [==============================] - 33s 711us/step - loss: 1.1015 - accuracy: 0.6660\n",
            "Epoch 43/65\n",
            "46905/46905 [==============================] - 34s 721us/step - loss: 1.0996 - accuracy: 0.6679\n",
            "Epoch 44/65\n",
            "46905/46905 [==============================] - 34s 716us/step - loss: 1.0783 - accuracy: 0.6732\n",
            "Epoch 45/65\n",
            "46905/46905 [==============================] - 34s 723us/step - loss: 1.0725 - accuracy: 0.6769\n",
            "Epoch 46/65\n",
            "46905/46905 [==============================] - 34s 714us/step - loss: 1.0616 - accuracy: 0.6791\n",
            "Epoch 47/65\n",
            "46905/46905 [==============================] - 33s 695us/step - loss: 1.0453 - accuracy: 0.6827\n",
            "Epoch 48/65\n",
            "46905/46905 [==============================] - 33s 706us/step - loss: 1.0325 - accuracy: 0.6860\n",
            "Epoch 49/65\n",
            "46905/46905 [==============================] - 33s 713us/step - loss: 1.0216 - accuracy: 0.6901\n",
            "Epoch 50/65\n",
            "46905/46905 [==============================] - 33s 699us/step - loss: 1.0139 - accuracy: 0.6939\n",
            "Epoch 51/65\n",
            "46905/46905 [==============================] - 33s 706us/step - loss: 1.0122 - accuracy: 0.6951\n",
            "Epoch 52/65\n",
            "46905/46905 [==============================] - 33s 704us/step - loss: 1.0042 - accuracy: 0.6969\n",
            "Epoch 53/65\n",
            "46905/46905 [==============================] - 33s 707us/step - loss: 0.9878 - accuracy: 0.7002\n",
            "Epoch 54/65\n",
            "46905/46905 [==============================] - 34s 723us/step - loss: 0.9802 - accuracy: 0.7040\n",
            "Epoch 55/65\n",
            "46905/46905 [==============================] - 33s 713us/step - loss: 0.9767 - accuracy: 0.7042\n",
            "Epoch 56/65\n",
            "46905/46905 [==============================] - 33s 711us/step - loss: 0.9757 - accuracy: 0.7056\n",
            "Epoch 57/65\n",
            "46905/46905 [==============================] - 33s 707us/step - loss: 0.9665 - accuracy: 0.7054\n",
            "Epoch 58/65\n",
            "46905/46905 [==============================] - 33s 709us/step - loss: 0.9540 - accuracy: 0.7114\n",
            "Epoch 59/65\n",
            "46905/46905 [==============================] - 33s 705us/step - loss: 0.9575 - accuracy: 0.7107\n",
            "Epoch 60/65\n",
            "46905/46905 [==============================] - 34s 716us/step - loss: 0.9482 - accuracy: 0.7151\n",
            "Epoch 61/65\n",
            "46905/46905 [==============================] - 34s 714us/step - loss: 0.9373 - accuracy: 0.7152\n",
            "Epoch 62/65\n",
            "46905/46905 [==============================] - 34s 717us/step - loss: 0.9331 - accuracy: 0.7162\n",
            "Epoch 63/65\n",
            "46905/46905 [==============================] - 34s 734us/step - loss: 0.9269 - accuracy: 0.7184\n",
            "Epoch 64/65\n",
            "46905/46905 [==============================] - 33s 701us/step - loss: 0.9254 - accuracy: 0.7193\n",
            "Epoch 65/65\n",
            "46905/46905 [==============================] - 33s 710us/step - loss: 0.9190 - accuracy: 0.7198\n",
            "[0.5601686404607704, 0.839984655380249]\n",
            "TRAIN: 46905 TEST: 5212 Epoch 1/65\n",
            "46905/46905 [==============================] - 33s 712us/step - loss: 3.3961 - accuracy: 0.0393\n",
            "Epoch 2/65\n",
            "46905/46905 [==============================] - 33s 708us/step - loss: 3.3861 - accuracy: 0.0474\n",
            "Epoch 3/65\n",
            "46905/46905 [==============================] - 32s 691us/step - loss: 3.3597 - accuracy: 0.0598\n",
            "Epoch 4/65\n",
            "46905/46905 [==============================] - 33s 700us/step - loss: 3.2496 - accuracy: 0.0862\n",
            "Epoch 5/65\n",
            "46905/46905 [==============================] - 33s 708us/step - loss: 3.0040 - accuracy: 0.1352\n",
            "Epoch 6/65\n",
            "46905/46905 [==============================] - 33s 701us/step - loss: 2.7807 - accuracy: 0.1875\n",
            "Epoch 7/65\n",
            "46905/46905 [==============================] - 33s 709us/step - loss: 2.6119 - accuracy: 0.2296\n",
            "Epoch 8/65\n",
            "46905/46905 [==============================] - 33s 711us/step - loss: 2.4852 - accuracy: 0.2638\n",
            "Epoch 9/65\n",
            "46905/46905 [==============================] - 33s 706us/step - loss: 2.3765 - accuracy: 0.2938\n",
            "Epoch 10/65\n",
            "46905/46905 [==============================] - 33s 702us/step - loss: 2.2868 - accuracy: 0.3186\n",
            "Epoch 11/65\n",
            "46905/46905 [==============================] - 33s 696us/step - loss: 2.1942 - accuracy: 0.3445\n",
            "Epoch 12/65\n",
            "46905/46905 [==============================] - 33s 700us/step - loss: 2.1060 - accuracy: 0.3696\n",
            "Epoch 13/65\n",
            "46905/46905 [==============================] - 33s 696us/step - loss: 2.0311 - accuracy: 0.3896\n",
            "Epoch 14/65\n",
            "46905/46905 [==============================] - 34s 715us/step - loss: 1.9624 - accuracy: 0.4159\n",
            "Epoch 15/65\n",
            "46905/46905 [==============================] - 33s 701us/step - loss: 1.8947 - accuracy: 0.4281\n",
            "Epoch 16/65\n",
            "46905/46905 [==============================] - 33s 697us/step - loss: 1.8209 - accuracy: 0.4513\n",
            "Epoch 17/65\n",
            "46905/46905 [==============================] - 34s 718us/step - loss: 1.7581 - accuracy: 0.4703\n",
            "Epoch 18/65\n",
            "46905/46905 [==============================] - 33s 703us/step - loss: 1.7085 - accuracy: 0.4830\n",
            "Epoch 19/65\n",
            "46905/46905 [==============================] - 33s 701us/step - loss: 1.6575 - accuracy: 0.4995\n",
            "Epoch 20/65\n",
            "46905/46905 [==============================] - 33s 705us/step - loss: 1.6138 - accuracy: 0.5120\n",
            "Epoch 21/65\n",
            "46905/46905 [==============================] - 33s 697us/step - loss: 1.5753 - accuracy: 0.5238\n",
            "Epoch 22/65\n",
            "46905/46905 [==============================] - 33s 705us/step - loss: 1.5275 - accuracy: 0.5348\n",
            "Epoch 23/65\n",
            "46905/46905 [==============================] - 33s 699us/step - loss: 1.4998 - accuracy: 0.5438\n",
            "Epoch 24/65\n",
            "46905/46905 [==============================] - 33s 701us/step - loss: 1.4687 - accuracy: 0.5531\n",
            "Epoch 25/65\n",
            "46905/46905 [==============================] - 33s 704us/step - loss: 1.4397 - accuracy: 0.5645\n",
            "Epoch 26/65\n",
            "46905/46905 [==============================] - 34s 719us/step - loss: 1.4089 - accuracy: 0.5734\n",
            "Epoch 27/65\n",
            "46905/46905 [==============================] - 34s 722us/step - loss: 1.3775 - accuracy: 0.5802\n",
            "Epoch 28/65\n",
            "46905/46905 [==============================] - 33s 710us/step - loss: 1.3621 - accuracy: 0.5891\n",
            "Epoch 29/65\n",
            "46905/46905 [==============================] - 34s 719us/step - loss: 1.3249 - accuracy: 0.5983\n",
            "Epoch 30/65\n",
            "46905/46905 [==============================] - 34s 717us/step - loss: 1.3102 - accuracy: 0.6028\n",
            "Epoch 31/65\n",
            "46905/46905 [==============================] - 33s 709us/step - loss: 1.2865 - accuracy: 0.6094\n",
            "Epoch 32/65\n",
            "46905/46905 [==============================] - 33s 700us/step - loss: 1.2560 - accuracy: 0.6194\n",
            "Epoch 33/65\n",
            "46905/46905 [==============================] - 33s 703us/step - loss: 1.2414 - accuracy: 0.6254\n",
            "Epoch 34/65\n",
            "46905/46905 [==============================] - 34s 726us/step - loss: 1.2227 - accuracy: 0.6283\n",
            "Epoch 35/65\n",
            "46905/46905 [==============================] - 34s 720us/step - loss: 1.2079 - accuracy: 0.6342\n",
            "Epoch 36/65\n",
            "46905/46905 [==============================] - 34s 718us/step - loss: 1.1977 - accuracy: 0.6376\n",
            "Epoch 37/65\n",
            "46905/46905 [==============================] - 34s 718us/step - loss: 1.1803 - accuracy: 0.6416\n",
            "Epoch 38/65\n",
            "46905/46905 [==============================] - 33s 711us/step - loss: 1.1634 - accuracy: 0.6491\n",
            "Epoch 39/65\n",
            "46905/46905 [==============================] - 33s 706us/step - loss: 1.1485 - accuracy: 0.6515\n",
            "Epoch 40/65\n",
            "46905/46905 [==============================] - 33s 700us/step - loss: 1.1304 - accuracy: 0.6585\n",
            "Epoch 41/65\n",
            "46905/46905 [==============================] - 33s 705us/step - loss: 1.1221 - accuracy: 0.6584\n",
            "Epoch 42/65\n",
            "46905/46905 [==============================] - 33s 709us/step - loss: 1.1142 - accuracy: 0.6638\n",
            "Epoch 43/65\n",
            "46905/46905 [==============================] - 34s 725us/step - loss: 1.1063 - accuracy: 0.6632\n",
            "Epoch 44/65\n",
            "46905/46905 [==============================] - 33s 714us/step - loss: 1.0896 - accuracy: 0.6686\n",
            "Epoch 45/65\n",
            "46905/46905 [==============================] - 34s 723us/step - loss: 1.0769 - accuracy: 0.6743\n",
            "Epoch 46/65\n",
            "46905/46905 [==============================] - 33s 709us/step - loss: 1.0702 - accuracy: 0.6752\n",
            "Epoch 47/65\n",
            "46905/46905 [==============================] - 33s 708us/step - loss: 1.0640 - accuracy: 0.6795\n",
            "Epoch 48/65\n",
            "46905/46905 [==============================] - 33s 713us/step - loss: 1.0532 - accuracy: 0.6814\n",
            "Epoch 49/65\n",
            "46905/46905 [==============================] - 33s 707us/step - loss: 1.0407 - accuracy: 0.6827\n",
            "Epoch 50/65\n",
            "46905/46905 [==============================] - 34s 719us/step - loss: 1.0292 - accuracy: 0.6883\n",
            "Epoch 51/65\n",
            "46905/46905 [==============================] - 33s 701us/step - loss: 1.0286 - accuracy: 0.6898\n",
            "Epoch 52/65\n",
            "46905/46905 [==============================] - 33s 710us/step - loss: 1.0210 - accuracy: 0.6921\n",
            "Epoch 53/65\n",
            "46905/46905 [==============================] - 34s 720us/step - loss: 1.0181 - accuracy: 0.6924\n",
            "Epoch 54/65\n",
            "46905/46905 [==============================] - 33s 711us/step - loss: 1.0028 - accuracy: 0.6951\n",
            "Epoch 55/65\n",
            "46905/46905 [==============================] - 34s 715us/step - loss: 0.9919 - accuracy: 0.6988\n",
            "Epoch 56/65\n",
            "46905/46905 [==============================] - 33s 702us/step - loss: 0.9918 - accuracy: 0.7004\n",
            "Epoch 57/65\n",
            "46905/46905 [==============================] - 33s 709us/step - loss: 0.9778 - accuracy: 0.7036\n",
            "Epoch 58/65\n",
            "46905/46905 [==============================] - 33s 706us/step - loss: 0.9723 - accuracy: 0.7058\n",
            "Epoch 59/65\n",
            "46905/46905 [==============================] - 33s 696us/step - loss: 0.9622 - accuracy: 0.7086\n",
            "Epoch 60/65\n",
            "46905/46905 [==============================] - 34s 715us/step - loss: 0.9605 - accuracy: 0.7091\n",
            "Epoch 61/65\n",
            "46905/46905 [==============================] - 33s 709us/step - loss: 0.9562 - accuracy: 0.7077\n",
            "Epoch 62/65\n",
            "46905/46905 [==============================] - 33s 704us/step - loss: 0.9579 - accuracy: 0.7094\n",
            "Epoch 63/65\n",
            "46905/46905 [==============================] - 33s 702us/step - loss: 0.9424 - accuracy: 0.7134\n",
            "Epoch 64/65\n",
            "46905/46905 [==============================] - 34s 727us/step - loss: 0.9369 - accuracy: 0.7163\n",
            "Epoch 65/65\n",
            "46905/46905 [==============================] - 33s 711us/step - loss: 0.9253 - accuracy: 0.7192\n",
            "[0.525536461223663, 0.8503453731536865]\n",
            "TRAIN: 46906 TEST: 5211 Epoch 1/65\n",
            "46906/46906 [==============================] - 34s 716us/step - loss: 3.3948 - accuracy: 0.0386\n",
            "Epoch 2/65\n",
            "46906/46906 [==============================] - 33s 694us/step - loss: 3.3831 - accuracy: 0.0452\n",
            "Epoch 3/65\n",
            "46906/46906 [==============================] - 33s 694us/step - loss: 3.3546 - accuracy: 0.0562\n",
            "Epoch 4/65\n",
            "46906/46906 [==============================] - 33s 707us/step - loss: 3.2677 - accuracy: 0.0799\n",
            "Epoch 5/65\n",
            "46906/46906 [==============================] - 33s 709us/step - loss: 3.0595 - accuracy: 0.1288\n",
            "Epoch 6/65\n",
            "46906/46906 [==============================] - 33s 704us/step - loss: 2.8147 - accuracy: 0.1808\n",
            "Epoch 7/65\n",
            "46906/46906 [==============================] - 33s 701us/step - loss: 2.6437 - accuracy: 0.2229\n",
            "Epoch 8/65\n",
            "46906/46906 [==============================] - 33s 712us/step - loss: 2.5068 - accuracy: 0.2600\n",
            "Epoch 9/65\n",
            "46906/46906 [==============================] - 33s 712us/step - loss: 2.3969 - accuracy: 0.2907\n",
            "Epoch 10/65\n",
            "46906/46906 [==============================] - 33s 704us/step - loss: 2.2904 - accuracy: 0.3194\n",
            "Epoch 11/65\n",
            "46906/46906 [==============================] - 33s 698us/step - loss: 2.1926 - accuracy: 0.3480\n",
            "Epoch 12/65\n",
            "46906/46906 [==============================] - 33s 703us/step - loss: 2.1015 - accuracy: 0.3730\n",
            "Epoch 13/65\n",
            "46906/46906 [==============================] - 33s 708us/step - loss: 2.0258 - accuracy: 0.3969\n",
            "Epoch 14/65\n",
            "46906/46906 [==============================] - 33s 709us/step - loss: 1.9492 - accuracy: 0.4181\n",
            "Epoch 15/65\n",
            "46906/46906 [==============================] - 33s 704us/step - loss: 1.8861 - accuracy: 0.4338\n",
            "Epoch 16/65\n",
            "46906/46906 [==============================] - 33s 708us/step - loss: 1.8141 - accuracy: 0.4534\n",
            "Epoch 17/65\n",
            "46906/46906 [==============================] - 34s 720us/step - loss: 1.7441 - accuracy: 0.4764\n",
            "Epoch 18/65\n",
            "46906/46906 [==============================] - 33s 698us/step - loss: 1.6920 - accuracy: 0.4895\n",
            "Epoch 19/65\n",
            "46906/46906 [==============================] - 33s 713us/step - loss: 1.6417 - accuracy: 0.5050\n",
            "Epoch 20/65\n",
            "46906/46906 [==============================] - 34s 719us/step - loss: 1.5894 - accuracy: 0.5194\n",
            "Epoch 21/65\n",
            "46906/46906 [==============================] - 34s 716us/step - loss: 1.5481 - accuracy: 0.5334\n",
            "Epoch 22/65\n",
            "46906/46906 [==============================] - 33s 707us/step - loss: 1.5034 - accuracy: 0.5422\n",
            "Epoch 23/65\n",
            "46906/46906 [==============================] - 33s 709us/step - loss: 1.4677 - accuracy: 0.5577\n",
            "Epoch 24/65\n",
            "46906/46906 [==============================] - 33s 702us/step - loss: 1.4315 - accuracy: 0.5678\n",
            "Epoch 25/65\n",
            "46906/46906 [==============================] - 33s 706us/step - loss: 1.4022 - accuracy: 0.5779\n",
            "Epoch 26/65\n",
            "46906/46906 [==============================] - 34s 727us/step - loss: 1.3711 - accuracy: 0.5868\n",
            "Epoch 27/65\n",
            "46906/46906 [==============================] - 33s 699us/step - loss: 1.3483 - accuracy: 0.5931\n",
            "Epoch 28/65\n",
            "46906/46906 [==============================] - 33s 698us/step - loss: 1.3142 - accuracy: 0.6037\n",
            "Epoch 29/65\n",
            "46906/46906 [==============================] - 33s 704us/step - loss: 1.2940 - accuracy: 0.6105\n",
            "Epoch 30/65\n",
            "46906/46906 [==============================] - 33s 704us/step - loss: 1.2748 - accuracy: 0.6149\n",
            "Epoch 31/65\n",
            "46906/46906 [==============================] - 33s 705us/step - loss: 1.2502 - accuracy: 0.6213\n",
            "Epoch 32/65\n",
            "46906/46906 [==============================] - 33s 712us/step - loss: 1.2277 - accuracy: 0.6282\n",
            "Epoch 33/65\n",
            "46906/46906 [==============================] - 33s 701us/step - loss: 1.2183 - accuracy: 0.6319\n",
            "Epoch 34/65\n",
            "46906/46906 [==============================] - 33s 708us/step - loss: 1.2004 - accuracy: 0.6387\n",
            "Epoch 35/65\n",
            "46906/46906 [==============================] - 33s 704us/step - loss: 1.1873 - accuracy: 0.6379\n",
            "Epoch 36/65\n",
            "46906/46906 [==============================] - 34s 720us/step - loss: 1.1646 - accuracy: 0.6492\n",
            "Epoch 37/65\n",
            "46906/46906 [==============================] - 33s 706us/step - loss: 1.1496 - accuracy: 0.6530\n",
            "Epoch 38/65\n",
            "46906/46906 [==============================] - 33s 709us/step - loss: 1.1420 - accuracy: 0.6553\n",
            "Epoch 39/65\n",
            "46906/46906 [==============================] - 33s 711us/step - loss: 1.1319 - accuracy: 0.6576\n",
            "Epoch 40/65\n",
            "46906/46906 [==============================] - 33s 714us/step - loss: 1.1148 - accuracy: 0.6655\n",
            "Epoch 41/65\n",
            "46906/46906 [==============================] - 33s 699us/step - loss: 1.1073 - accuracy: 0.6670\n",
            "Epoch 42/65\n",
            "46906/46906 [==============================] - 33s 705us/step - loss: 1.0860 - accuracy: 0.6724\n",
            "Epoch 43/65\n",
            "46906/46906 [==============================] - 33s 694us/step - loss: 1.0875 - accuracy: 0.6729\n",
            "Epoch 44/65\n",
            "46906/46906 [==============================] - 33s 696us/step - loss: 1.0743 - accuracy: 0.6739\n",
            "Epoch 45/65\n",
            "46906/46906 [==============================] - 34s 719us/step - loss: 1.0580 - accuracy: 0.6796\n",
            "Epoch 46/65\n",
            "46906/46906 [==============================] - 33s 705us/step - loss: 1.0438 - accuracy: 0.6835\n",
            "Epoch 47/65\n",
            "46906/46906 [==============================] - 33s 708us/step - loss: 1.0427 - accuracy: 0.6865\n",
            "Epoch 48/65\n",
            "46906/46906 [==============================] - 33s 711us/step - loss: 1.0349 - accuracy: 0.6879\n",
            "Epoch 49/65\n",
            "46906/46906 [==============================] - 33s 701us/step - loss: 1.0317 - accuracy: 0.6882\n",
            "Epoch 50/65\n",
            "46906/46906 [==============================] - 33s 701us/step - loss: 1.0223 - accuracy: 0.6912\n",
            "Epoch 51/65\n",
            "46906/46906 [==============================] - 33s 693us/step - loss: 1.0056 - accuracy: 0.6961\n",
            "Epoch 52/65\n",
            "46906/46906 [==============================] - 33s 698us/step - loss: 0.9942 - accuracy: 0.6993\n",
            "Epoch 53/65\n",
            "46906/46906 [==============================] - 33s 695us/step - loss: 0.9960 - accuracy: 0.6997\n",
            "Epoch 54/65\n",
            "46906/46906 [==============================] - 33s 701us/step - loss: 0.9871 - accuracy: 0.6998\n",
            "Epoch 55/65\n",
            "46906/46906 [==============================] - 33s 710us/step - loss: 0.9842 - accuracy: 0.7044\n",
            "Epoch 56/65\n",
            "46906/46906 [==============================] - 33s 709us/step - loss: 0.9796 - accuracy: 0.7043\n",
            "Epoch 57/65\n",
            "46906/46906 [==============================] - 33s 694us/step - loss: 0.9655 - accuracy: 0.7087\n",
            "Epoch 58/65\n",
            "46906/46906 [==============================] - 33s 697us/step - loss: 0.9644 - accuracy: 0.7085\n",
            "Epoch 59/65\n",
            "46906/46906 [==============================] - 33s 703us/step - loss: 0.9545 - accuracy: 0.7107\n",
            "Epoch 60/65\n",
            "46906/46906 [==============================] - 33s 706us/step - loss: 0.9516 - accuracy: 0.7110\n",
            "Epoch 61/65\n",
            "46906/46906 [==============================] - 32s 691us/step - loss: 0.9406 - accuracy: 0.7158\n",
            "Epoch 62/65\n",
            "46906/46906 [==============================] - 33s 712us/step - loss: 0.9435 - accuracy: 0.7140\n",
            "Epoch 63/65\n",
            "46906/46906 [==============================] - 33s 704us/step - loss: 0.9383 - accuracy: 0.7173\n",
            "Epoch 64/65\n",
            "46906/46906 [==============================] - 33s 704us/step - loss: 0.9302 - accuracy: 0.7181\n",
            "Epoch 65/65\n",
            "46906/46906 [==============================] - 34s 716us/step - loss: 0.9228 - accuracy: 0.7217\n",
            "[0.5666816342508374, 0.8361158967018127]\n",
            "TRAIN: 46906 TEST: 5211 Epoch 1/65\n",
            "46906/46906 [==============================] - 33s 693us/step - loss: 3.3934 - accuracy: 0.0402\n",
            "Epoch 2/65\n",
            "46906/46906 [==============================] - 33s 703us/step - loss: 3.3810 - accuracy: 0.0463\n",
            "Epoch 3/65\n",
            "46906/46906 [==============================] - 33s 704us/step - loss: 3.3530 - accuracy: 0.0577\n",
            "Epoch 4/65\n",
            "46906/46906 [==============================] - 33s 700us/step - loss: 3.2820 - accuracy: 0.0745\n",
            "Epoch 5/65\n",
            "46906/46906 [==============================] - 33s 705us/step - loss: 3.1032 - accuracy: 0.1142\n",
            "Epoch 6/65\n",
            "46906/46906 [==============================] - 33s 705us/step - loss: 2.8465 - accuracy: 0.1715\n",
            "Epoch 7/65\n",
            "46906/46906 [==============================] - 33s 712us/step - loss: 2.6530 - accuracy: 0.2201\n",
            "Epoch 8/65\n",
            "46906/46906 [==============================] - 34s 716us/step - loss: 2.5094 - accuracy: 0.2583\n",
            "Epoch 9/65\n",
            "46906/46906 [==============================] - 33s 704us/step - loss: 2.3905 - accuracy: 0.2924\n",
            "Epoch 10/65\n",
            "46906/46906 [==============================] - 34s 715us/step - loss: 2.2851 - accuracy: 0.3198\n",
            "Epoch 11/65\n",
            "46906/46906 [==============================] - 33s 702us/step - loss: 2.1833 - accuracy: 0.3495\n",
            "Epoch 12/65\n",
            "46906/46906 [==============================] - 33s 707us/step - loss: 2.0931 - accuracy: 0.3748\n",
            "Epoch 13/65\n",
            "46906/46906 [==============================] - 34s 719us/step - loss: 2.0126 - accuracy: 0.3991\n",
            "Epoch 14/65\n",
            "46906/46906 [==============================] - 33s 707us/step - loss: 1.9280 - accuracy: 0.4239\n",
            "Epoch 15/65\n",
            "46906/46906 [==============================] - 32s 689us/step - loss: 1.8511 - accuracy: 0.4439\n",
            "Epoch 16/65\n",
            "46906/46906 [==============================] - 33s 705us/step - loss: 1.7797 - accuracy: 0.4668\n",
            "Epoch 17/65\n",
            "46906/46906 [==============================] - 33s 709us/step - loss: 1.7253 - accuracy: 0.4798\n",
            "Epoch 18/65\n",
            "46906/46906 [==============================] - 34s 723us/step - loss: 1.6563 - accuracy: 0.5026\n",
            "Epoch 19/65\n",
            "46906/46906 [==============================] - 33s 707us/step - loss: 1.6002 - accuracy: 0.5169\n",
            "Epoch 20/65\n",
            "46906/46906 [==============================] - 33s 699us/step - loss: 1.5520 - accuracy: 0.5293\n",
            "Epoch 21/65\n",
            "46906/46906 [==============================] - 33s 700us/step - loss: 1.5055 - accuracy: 0.5475\n",
            "Epoch 22/65\n",
            "46906/46906 [==============================] - 34s 717us/step - loss: 1.4673 - accuracy: 0.5558\n",
            "Epoch 23/65\n",
            "46906/46906 [==============================] - 33s 706us/step - loss: 1.4377 - accuracy: 0.5673\n",
            "Epoch 24/65\n",
            "46906/46906 [==============================] - 33s 709us/step - loss: 1.4063 - accuracy: 0.5738\n",
            "Epoch 25/65\n",
            "46906/46906 [==============================] - 33s 706us/step - loss: 1.3670 - accuracy: 0.5880\n",
            "Epoch 26/65\n",
            "46906/46906 [==============================] - 33s 711us/step - loss: 1.3526 - accuracy: 0.5917\n",
            "Epoch 27/65\n",
            "46906/46906 [==============================] - 34s 721us/step - loss: 1.3228 - accuracy: 0.6021\n",
            "Epoch 28/65\n",
            "46906/46906 [==============================] - 33s 705us/step - loss: 1.2953 - accuracy: 0.6067\n",
            "Epoch 29/65\n",
            "46906/46906 [==============================] - 33s 708us/step - loss: 1.2798 - accuracy: 0.6129\n",
            "Epoch 30/65\n",
            "46906/46906 [==============================] - 34s 719us/step - loss: 1.2512 - accuracy: 0.6207\n",
            "Epoch 31/65\n",
            "46906/46906 [==============================] - 33s 712us/step - loss: 1.2425 - accuracy: 0.6247\n",
            "Epoch 32/65\n",
            "46906/46906 [==============================] - 33s 712us/step - loss: 1.2197 - accuracy: 0.6312\n",
            "Epoch 33/65\n",
            "46906/46906 [==============================] - 33s 702us/step - loss: 1.2048 - accuracy: 0.6360\n",
            "Epoch 34/65\n",
            "46906/46906 [==============================] - 33s 714us/step - loss: 1.1929 - accuracy: 0.6412\n",
            "Epoch 35/65\n",
            "46906/46906 [==============================] - 33s 705us/step - loss: 1.1711 - accuracy: 0.6464\n",
            "Epoch 36/65\n",
            "46906/46906 [==============================] - 34s 721us/step - loss: 1.1639 - accuracy: 0.6473\n",
            "Epoch 37/65\n",
            "46906/46906 [==============================] - 33s 709us/step - loss: 1.1499 - accuracy: 0.6522\n",
            "Epoch 38/65\n",
            "46906/46906 [==============================] - 33s 700us/step - loss: 1.1371 - accuracy: 0.6566\n",
            "Epoch 39/65\n",
            "46906/46906 [==============================] - 33s 704us/step - loss: 1.1207 - accuracy: 0.6618\n",
            "Epoch 40/65\n",
            "46906/46906 [==============================] - 34s 716us/step - loss: 1.1110 - accuracy: 0.6632\n",
            "Epoch 41/65\n",
            "46906/46906 [==============================] - 34s 718us/step - loss: 1.1063 - accuracy: 0.6658\n",
            "Epoch 42/65\n",
            "46906/46906 [==============================] - 33s 704us/step - loss: 1.0893 - accuracy: 0.6710\n",
            "Epoch 43/65\n",
            "46906/46906 [==============================] - 33s 697us/step - loss: 1.0841 - accuracy: 0.6730\n",
            "Epoch 44/65\n",
            "46906/46906 [==============================] - 33s 704us/step - loss: 1.0653 - accuracy: 0.6778\n",
            "Epoch 45/65\n",
            "46906/46906 [==============================] - 33s 702us/step - loss: 1.0599 - accuracy: 0.6787\n",
            "Epoch 46/65\n",
            "46906/46906 [==============================] - 34s 726us/step - loss: 1.0509 - accuracy: 0.6816\n",
            "Epoch 47/65\n",
            "46906/46906 [==============================] - 34s 717us/step - loss: 1.0456 - accuracy: 0.6826\n",
            "Epoch 48/65\n",
            "46906/46906 [==============================] - 33s 706us/step - loss: 1.0440 - accuracy: 0.6846\n",
            "Epoch 49/65\n",
            "46906/46906 [==============================] - 33s 711us/step - loss: 1.0319 - accuracy: 0.6895\n",
            "Epoch 50/65\n",
            "46906/46906 [==============================] - 33s 713us/step - loss: 1.0220 - accuracy: 0.6900\n",
            "Epoch 51/65\n",
            "46906/46906 [==============================] - 33s 707us/step - loss: 1.0139 - accuracy: 0.6943\n",
            "Epoch 52/65\n",
            "46906/46906 [==============================] - 33s 697us/step - loss: 1.0006 - accuracy: 0.6974\n",
            "Epoch 53/65\n",
            "46906/46906 [==============================] - 33s 698us/step - loss: 1.0038 - accuracy: 0.6955\n",
            "Epoch 54/65\n",
            "46906/46906 [==============================] - 33s 714us/step - loss: 0.9972 - accuracy: 0.6983\n",
            "Epoch 55/65\n",
            "46906/46906 [==============================] - 34s 731us/step - loss: 0.9796 - accuracy: 0.7024\n",
            "Epoch 56/65\n",
            "46906/46906 [==============================] - 33s 706us/step - loss: 0.9786 - accuracy: 0.7043\n",
            "Epoch 57/65\n",
            "46906/46906 [==============================] - 33s 700us/step - loss: 0.9688 - accuracy: 0.7074\n",
            "Epoch 58/65\n",
            "46906/46906 [==============================] - 33s 704us/step - loss: 0.9686 - accuracy: 0.7060\n",
            "Epoch 59/65\n",
            "46906/46906 [==============================] - 33s 705us/step - loss: 0.9546 - accuracy: 0.7106\n",
            "Epoch 60/65\n",
            "46906/46906 [==============================] - 33s 703us/step - loss: 0.9532 - accuracy: 0.7102\n",
            "Epoch 61/65\n",
            "46906/46906 [==============================] - 33s 695us/step - loss: 0.9450 - accuracy: 0.7114\n",
            "Epoch 62/65\n",
            "46906/46906 [==============================] - 33s 694us/step - loss: 0.9400 - accuracy: 0.7152\n",
            "Epoch 63/65\n",
            "46906/46906 [==============================] - 33s 710us/step - loss: 0.9346 - accuracy: 0.7175\n",
            "Epoch 64/65\n",
            "46906/46906 [==============================] - 34s 722us/step - loss: 0.9278 - accuracy: 0.7186\n",
            "Epoch 65/65\n",
            "46906/46906 [==============================] - 34s 721us/step - loss: 0.9277 - accuracy: 0.7186\n",
            "[0.554815593326968, 0.8389944434165955]\n",
            "TRAIN: 46906 TEST: 5211 Epoch 1/65\n",
            "46906/46906 [==============================] - 33s 706us/step - loss: 3.3932 - accuracy: 0.0395\n",
            "Epoch 2/65\n",
            "46906/46906 [==============================] - 33s 705us/step - loss: 3.3765 - accuracy: 0.0483\n",
            "Epoch 3/65\n",
            "46906/46906 [==============================] - 33s 710us/step - loss: 3.3235 - accuracy: 0.0675\n",
            "Epoch 4/65\n",
            "46906/46906 [==============================] - 33s 714us/step - loss: 3.1846 - accuracy: 0.1055\n",
            "Epoch 5/65\n",
            "46906/46906 [==============================] - 33s 699us/step - loss: 2.9467 - accuracy: 0.1489\n",
            "Epoch 6/65\n",
            "46906/46906 [==============================] - 33s 711us/step - loss: 2.7327 - accuracy: 0.1970\n",
            "Epoch 7/65\n",
            "46906/46906 [==============================] - 33s 711us/step - loss: 2.5753 - accuracy: 0.2368\n",
            "Epoch 8/65\n",
            "46906/46906 [==============================] - 35s 747us/step - loss: 2.4609 - accuracy: 0.2712\n",
            "Epoch 9/65\n",
            "46906/46906 [==============================] - 33s 706us/step - loss: 2.3554 - accuracy: 0.3009\n",
            "Epoch 10/65\n",
            "46906/46906 [==============================] - 34s 720us/step - loss: 2.2668 - accuracy: 0.3332\n",
            "Epoch 11/65\n",
            "46906/46906 [==============================] - 34s 717us/step - loss: 2.1754 - accuracy: 0.3535\n",
            "Epoch 12/65\n",
            "46906/46906 [==============================] - 33s 711us/step - loss: 2.0955 - accuracy: 0.3776\n",
            "Epoch 13/65\n",
            "46906/46906 [==============================] - 33s 701us/step - loss: 2.0306 - accuracy: 0.3946\n",
            "Epoch 14/65\n",
            "46906/46906 [==============================] - 33s 710us/step - loss: 1.9619 - accuracy: 0.4132\n",
            "Epoch 15/65\n",
            "46906/46906 [==============================] - 33s 707us/step - loss: 1.9012 - accuracy: 0.4293\n",
            "Epoch 16/65\n",
            "46906/46906 [==============================] - 33s 697us/step - loss: 1.8367 - accuracy: 0.4505\n",
            "Epoch 17/65\n",
            "46906/46906 [==============================] - 33s 701us/step - loss: 1.7724 - accuracy: 0.4663\n",
            "Epoch 18/65\n",
            "46906/46906 [==============================] - 34s 715us/step - loss: 1.7295 - accuracy: 0.4806\n",
            "Epoch 19/65\n",
            "46906/46906 [==============================] - 33s 704us/step - loss: 1.6816 - accuracy: 0.4933\n",
            "Epoch 20/65\n",
            "46906/46906 [==============================] - 34s 726us/step - loss: 1.6244 - accuracy: 0.5111\n",
            "Epoch 21/65\n",
            "46906/46906 [==============================] - 33s 714us/step - loss: 1.5788 - accuracy: 0.5239\n",
            "Epoch 22/65\n",
            "46906/46906 [==============================] - 33s 701us/step - loss: 1.5356 - accuracy: 0.5382\n",
            "Epoch 23/65\n",
            "46906/46906 [==============================] - 33s 699us/step - loss: 1.4987 - accuracy: 0.5451\n",
            "Epoch 24/65\n",
            "46906/46906 [==============================] - 33s 712us/step - loss: 1.4608 - accuracy: 0.5610\n",
            "Epoch 25/65\n",
            "46906/46906 [==============================] - 33s 705us/step - loss: 1.4318 - accuracy: 0.5662\n",
            "Epoch 26/65\n",
            "46906/46906 [==============================] - 33s 699us/step - loss: 1.4049 - accuracy: 0.5745\n",
            "Epoch 27/65\n",
            "46906/46906 [==============================] - 34s 726us/step - loss: 1.3832 - accuracy: 0.5809\n",
            "Epoch 28/65\n",
            "46906/46906 [==============================] - 33s 696us/step - loss: 1.3616 - accuracy: 0.5881\n",
            "Epoch 29/65\n",
            "46906/46906 [==============================] - 33s 714us/step - loss: 1.3331 - accuracy: 0.5974\n",
            "Epoch 30/65\n",
            "46906/46906 [==============================] - 33s 705us/step - loss: 1.3086 - accuracy: 0.6045\n",
            "Epoch 31/65\n",
            "46906/46906 [==============================] - 33s 704us/step - loss: 1.2884 - accuracy: 0.6120\n",
            "Epoch 32/65\n",
            "46906/46906 [==============================] - 33s 702us/step - loss: 1.2779 - accuracy: 0.6114\n",
            "Epoch 33/65\n",
            "46906/46906 [==============================] - 33s 709us/step - loss: 1.2560 - accuracy: 0.6211\n",
            "Epoch 34/65\n",
            "46906/46906 [==============================] - 33s 708us/step - loss: 1.2353 - accuracy: 0.6280\n",
            "Epoch 35/65\n",
            "46906/46906 [==============================] - 33s 713us/step - loss: 1.2201 - accuracy: 0.6292\n",
            "Epoch 36/65\n",
            "46906/46906 [==============================] - 33s 714us/step - loss: 1.2065 - accuracy: 0.6333\n",
            "Epoch 37/65\n",
            "46906/46906 [==============================] - 33s 694us/step - loss: 1.1980 - accuracy: 0.6383\n",
            "Epoch 38/65\n",
            "46906/46906 [==============================] - 33s 701us/step - loss: 1.1823 - accuracy: 0.6417\n",
            "Epoch 39/65\n",
            "46906/46906 [==============================] - 33s 703us/step - loss: 1.1705 - accuracy: 0.6489\n",
            "Epoch 40/65\n",
            "46906/46906 [==============================] - 33s 696us/step - loss: 1.1602 - accuracy: 0.6476\n",
            "Epoch 41/65\n",
            "46906/46906 [==============================] - 33s 707us/step - loss: 1.1420 - accuracy: 0.6517\n",
            "Epoch 42/65\n",
            "46906/46906 [==============================] - 33s 709us/step - loss: 1.1398 - accuracy: 0.6565\n",
            "Epoch 43/65\n",
            "46906/46906 [==============================] - 33s 703us/step - loss: 1.1165 - accuracy: 0.6638\n",
            "Epoch 44/65\n",
            "46906/46906 [==============================] - 33s 710us/step - loss: 1.1153 - accuracy: 0.6636\n",
            "Epoch 45/65\n",
            "46906/46906 [==============================] - 33s 711us/step - loss: 1.0995 - accuracy: 0.6705\n",
            "Epoch 46/65\n",
            "46906/46906 [==============================] - 34s 724us/step - loss: 1.0994 - accuracy: 0.6673\n",
            "Epoch 47/65\n",
            "46906/46906 [==============================] - 34s 721us/step - loss: 1.0773 - accuracy: 0.6731\n",
            "Epoch 48/65\n",
            "46906/46906 [==============================] - 33s 706us/step - loss: 1.0728 - accuracy: 0.6764\n",
            "Epoch 49/65\n",
            "46906/46906 [==============================] - 33s 710us/step - loss: 1.0657 - accuracy: 0.6790\n",
            "Epoch 50/65\n",
            "46906/46906 [==============================] - 33s 707us/step - loss: 1.0591 - accuracy: 0.6815\n",
            "Epoch 51/65\n",
            "46906/46906 [==============================] - 33s 710us/step - loss: 1.0504 - accuracy: 0.6835\n",
            "Epoch 52/65\n",
            "46906/46906 [==============================] - 33s 708us/step - loss: 1.0347 - accuracy: 0.6863\n",
            "Epoch 53/65\n",
            "46906/46906 [==============================] - 33s 705us/step - loss: 1.0272 - accuracy: 0.6922\n",
            "Epoch 54/65\n",
            "46906/46906 [==============================] - 33s 704us/step - loss: 1.0190 - accuracy: 0.6907\n",
            "Epoch 55/65\n",
            "46906/46906 [==============================] - 34s 718us/step - loss: 1.0065 - accuracy: 0.6983\n",
            "Epoch 56/65\n",
            "46906/46906 [==============================] - 34s 723us/step - loss: 1.0088 - accuracy: 0.6968\n",
            "Epoch 57/65\n",
            "46906/46906 [==============================] - 33s 711us/step - loss: 0.9969 - accuracy: 0.6991\n",
            "Epoch 58/65\n",
            "46906/46906 [==============================] - 33s 707us/step - loss: 0.9881 - accuracy: 0.7004\n",
            "Epoch 59/65\n",
            "46906/46906 [==============================] - 33s 698us/step - loss: 0.9817 - accuracy: 0.7036\n",
            "Epoch 60/65\n",
            "46906/46906 [==============================] - 33s 705us/step - loss: 0.9795 - accuracy: 0.7030\n",
            "Epoch 61/65\n",
            "46906/46906 [==============================] - 33s 704us/step - loss: 0.9737 - accuracy: 0.7081\n",
            "Epoch 62/65\n",
            "46906/46906 [==============================] - 33s 709us/step - loss: 0.9597 - accuracy: 0.7107\n",
            "Epoch 63/65\n",
            "46906/46906 [==============================] - 33s 714us/step - loss: 0.9643 - accuracy: 0.7075\n",
            "Epoch 64/65\n",
            "46906/46906 [==============================] - 34s 714us/step - loss: 0.9550 - accuracy: 0.7120\n",
            "Epoch 65/65\n",
            "46906/46906 [==============================] - 34s 720us/step - loss: 0.9488 - accuracy: 0.7135\n",
            "[0.5617658158818217, 0.8378430008888245]\n",
            "[[0.5928769217416678, 0.8294320702552795], [0.6504284438955171, 0.8150421977043152], [0.5788970370751935, 0.839984655380249], [0.6253676089706187, 0.8148503303527832], [0.5648825041898287, 0.839984655380249], [0.5601686404607704, 0.839984655380249], [0.525536461223663, 0.8503453731536865], [0.5666816342508374, 0.8361158967018127], [0.554815593326968, 0.8389944434165955], [0.5617658158818217, 0.8378430008888245]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H5JtpjC00uh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "02faece7-4ff4-420b-f1fc-6753acdc7467"
      },
      "source": [
        "sc = [s[1] for s in scores]\n",
        "sc = np.array(sc)\n",
        "import pickle\n",
        "name = \"cnn\"\n",
        "best_model = modelli[sc.argmax()]\n",
        "filename = '/content/drive/My Drive/ModelliSalvati/Audio/Classificatori/'+name+'.sav'\n",
        "pickle.dump(best_model, open(filename, 'wb'))\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(sc,scaley=False,color=\"b\")\n",
        "plt.title(name+\" KFOLD Cross Validation\")\n",
        "plt.savefig(\"/content/drive/My Drive/ModelliSalvati/Audio/Classificatori/\"+name+\".png\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXc0lEQVR4nO3deZRcZZ3G8e9DJxEhgQS6DWYjEUNIdMSlDduMMqIILuGc0XHAbVSU4xxxRTQuBxQdBXUU58gwRlziRkRkxqhRHBfGFaRRR01isI1AOiGkEyAkQEKW3/zx3rJvV6q7Kp3qrvTbz+ece7rq3rfu/dXtrue+971V1YoIzMxs9Duk1QWYmVlzONDNzDLhQDczy4QD3cwsEw50M7NMONDNzDLhQDcbRSTdJOm1xe2XSfp+I22HsJ1ZkrZLahtqrTbyHOi2XySdLqmndH+CpBsk/VzSEZLeJ2lXEQaV6R2l9i+Q9CtJD0raIukrkmaUlr9K0s8G2PZNknZI2ibpAUm3SVos6VF1al4oaYWk+yXdW2z/1c3YH/urqPcnNea3S3pE0hMbXVdEfCUizmxSXXdIenZp3XdFxMSI2NOM9dvIcKDbkBVBegMwGTgzIh4oFn2tCIPK9JGi/YuBrwJXAu3AE4CdwM8kTWlwsxdGxCTgscBFwLnACkkaoMZTgB8B/ws8Hjga+Bfg7AHaj2uwjqH6MnCqpDlV888Ffh8Rfxjm7VvGHOgZkTSz6C33Fr3fTxXzXyXpZ5I+Juk+SX+RdHbpcTdJ+kDRy94m6fuS2uts6zDgW8A44PkR8WCd9gL+DfhgRHw1Ih6OiI3Aa4HtwFv357lGxIMRcROwCDgFeP4ATT8KLI2IKyJicyS3RcRLirpOl9Qj6Z2SNgKfl/QoSVdK2lBMV1bOAoqe9LdLvf2fSjqkWPZOSeuLfbhG0hk16u4hHWBeUbXolcAXJU0p1t9b/K6+XT6Dqdqn/c5mJD1H0h8lbS1+9yotO07Sj4q/i83FmdHkYtmXgFnAtypnVJJmS4rKAU7SNEnLi+fcLel1pXW/T9J1kr5YPPeVkjoH+t3Z8HGgZ6IY6/w2cCcwG5gOLCs1OQlYQ+oZfwT4bFWv9qXAq4HHABOAtw+yuUcB3wV2AOdExMMNlDiPFBpfL8+MiL3AN4DnNLCOfUTEXUAX8HfVy4qDzinA9XVWcwxwFHAscAHwHuBk4MnAicBC4L1F24uAHqADmAq8GwhJ84ALgacXZxDPBe4YYHtLKQV68dgnk85eDgE+X9QyC3gY+FSd+ikOwDcUdbYDfwZOKzcBPgxMA+YDM4H3AUTEK4C7gBeWz6iqLCue9zTgxcCHJD2rtHxR0WYysLyRmq35HOj5WEh6sV1c9F53RER5LPrOiPhMMSa6lDRkMbW0/PMRcXsRzteRAmYgk0hBuTQidtZY/pKiB1uZppFCBuDuGu3vLi0fig2kQK42hfQ3XmubZXuBSyNiZ/H8XwZcFhGbIqIXeD99AbyLtO+OjYhdEfHTSF+ItId0oFsgaXxE3BERfx5ge/8FTJV0anH/lcB3I6I3IrZExDci4qGI2Ab8K/DMBvbB84CVEXF9ROwiDWttrCyMiO6I+J/iOfYCH29wvUiaSTo4vLP4u/otcE1Rd8XPImJF8ff1JdKB0EaYAz0fM0mhvXuA5eUX90PFzYm1lgMPVS2rtpk05rtU0nNrLL8uIiaXpg3FYyCFYbXHlpYPxXTg3hrz7yOFda1tlvVGxI7S/WmkM52KO4t5kIZwuoHvS1oraTGkwATeQur1bpK0rDiQ7aPY/18HXlmcJb0M+CKkswpJn5Z0p6QHgJ8Ak1X/3SbTgHWlbUT5vqSpRU3ri/V+mcYPotOAe4sDTMWdpP1eUf33c+gIXI+wKg70fKwDZo3UiygibgBeB1wv6e8beMga0in7P5ZnFuPPLwJ+OJQ6it7j04Cf1qjxIeCXxfoHU/2VoxtIQx4Vs4p5RMS2iLgoIh5HGmZ4W2WsvLg28LfFYwO4YpBtLgVeQhpqmkS6HgFpSGcecFJEHAE8o/JU6zyHu0kH9dQ4HShmlpZ/qKjpb4r1vrxqnYN97eoG4ChJk0rzZgHr69RkI8yBno9fkV7Ul0s6XNKhkk6r96ADERHXksaNv1lvW0WP8e3AeyW9tKjvGNKp+xHAJ0rNVSz/61S9vqIn+0zgm6TnvmKATb8DeJWkiyUdXTz2REnLBmgPcG1RZ0cxNn0JqUdbedvl44vA3EoaatkraZ6kZxUXT3eQxr73DrKNnwL3A0uAZRHxSDF/UvHY+yUdBVw6yDrKvgM8QdI/FAf1N5GuDVRMIl183ippOnBx1ePvAR5Xa8URsQ74BfDh4vfxJOB8in1iBw8HeiaKscsXkt6adxepN/xPI7DdpaRe5XckLazT9muksei3AluAVcCjgdMiYkup6amkUPvrVDrz+JSkbaQAupJ0QfWs4uJqrW3+AnhWMa2VdC8pRAc6AAB8kHSh9XfA74FfF/MA5gI/IIXjL4H/iIgfk8bPLycNHW0kXVx+1yD7IkjDLMcWPyuuLPbJZuBm4HuD1Fle32bS2c/lpH07F/h5qcn7gaeSDkLfIV1ALfsw6SB2v6RaF8TPI11s30C6BnBpRPygkdps5Mj/4MLMLA/uoZuZZaJuoEv6nKRNkmp+gk3JvxcfNvidpKc2v0wzM6unkR76F4CzBll+Nmm8bi7pQxlXH3hZZma2v+oGekT8hNrv8a04B/hi8ZHqm0nvma33vl8zM2uyZrxneTqlDzCQ3l0xnRqfzpN0AakXz+GHH/60E044oQmbNzMbO2677bbNEdFRa9mIfpIrIpaQ3jJGZ2dndHV1jeTmzcxGPUl3DrSsGe9yWU//T6TNwJ8gMzMbcc0I9OUU30kh6WRga0TU+zIkMzNrsrpDLpKuBU4H2pX+U82lwHiAiPhP0ifunkf6wqKHSF/BamZmI6xuoEfEeXWWB/CGplVkZmZD4k+KmpllwoFuZpYJB7qZWSYc6GZmmXCgm5llwoFuZpYJB7qZWSYc6GZmmXCgm5llwoFuZpYJB7qZWSYc6GZmmXCgm5llwoFuZpYJB7qZWSYc6GZmmXCgm5llwoFuZpYJB7qZWSYc6GZmmXCgm5llwoFuZpYJB7qZWSYc6GZmmXCgm5llwoFuZpaJca0uwMwas2cP3H8/3Hdfmu69t+/2QNPu3fCYx8Axx8DUqWmq3K787OiAcU6CLPjXaDaCdu/uH8r7Mz3wwODrPvRQmDKlb5oxIwX1pk1w882wcSM89NC+j5OgvX3w0K/8bG+Htrbh2Td24Bzoo9DWrbB6dZr++EcYPx7mz4cFC2DePDjssFZXOHIioKcn7YtVq6C7G3btanVV/YO73JPetm3wx9UK5Sc9qf+8gaZDD61f1/btcM89Kdzvuaf/7crP7u708+GH9338IYekHv1goV/5efTRqf1Q7d2bfpe7dqX9Wbk9lPuVeZXncMgh6UBWuV1vanbb9nY44oih75uBONAPUhHpBVYJ7vJ099197SZMSKfie/ak+xIce2wK9/nz+4J+/nyYPLk1z6UZ9uyBtWv7gru8P7Zv72t35JHw6Ee3rs6Ktra0v6dMgVmz4MQTmxfKB2LixDQdd9zg7SLSwWeg0K/8XLMm3d65c991tLWl4Z6pU+Hww/c/jPfuHZ59cDC4+mp4/eubv95RF+jd3XD77akXcMwxqbcwfnyrqxq6PXvgjjtqB/fWrX3tJk1KoXzmmX1BPX8+zJmT/vD/9Kd9w+6HP+z/QnvsY/cN+fnz0wtOGvGnXtPOnen3W3kOledz++39n8v06an217ym/3Pq6Ghd7TmRUg/yiCNg7tzB20ak4aDqsK/c3rgx9fYnTkyv1fHj01BQ5XYj94fymFr3pfR6qUwR/e8PNjWz7UknDdPvLSKGZ811dHZ2RldX134/7oorYPHi/vPK43+VoK91u739wE4BD8TOnX2hWx1UO3b0tZs6tX9gV6Zp0/Y/dMsHi8r2Kj/Lp/5Tpuwb8gsWwMyZw7e/tm/vf/Cq1PXnP/f1zKR0wKrUVfl5wgmpJ242Fkm6LSI6ay4bbYG+eXPqpZd7A9W3Kz2Cam1tqQc3WOhXbk+ZMrRe6wMPpHHt6t52dVDNnl07uKdM2f9t7q8I2LChf2++cru3t6/dYYel8KwO1OOOa/xdEVu27HvmsGoVrFvX12b8+NQLrD6gHH/8wTF8YnYwySrQGxGReoC1wr7W7VoX0SZM6H/Fv1bo79mzb3CvX9+3jkpQVfd+jz/+4L1wuXlz7Z5zdQAff3z/8J03b9/wXrWq9gGien8cd9zoHjYzG0ljLtD3R0R690F1D79W8G/aVPtCzcSJfUFVnvanJ3uw27at78yj3Nsun3lUTJ5c+6LsrFmtG/Iyy8Vggd5Q3Eg6C/gk0AZcExGXVy2fBSwFJhdtFkfEigOqeoRIcNRRaZo/f/C2e/akXmgl6KUU5DNmHDwXFYfLpEnw9KenqWzHjnRtYM2atA8XLDi4LrKajSV1e+iS2oDbgecAPcCtwHkRsarUZgnwm4i4WtICYEVEzB5svQdLD93MbDQZrIfeyAnwQqA7ItZGxCPAMuCcqjYBVN4mfySwYajFmpnZ0DQS6NOB0iUxeop5Ze8DXi6pB1gBvLHWiiRdIKlLUldv+WqZmZkdsGZdojoP+EJEzACeB3xJ0j7rjoglEdEZEZ0d/gSImVlTNRLo64GZpfszinll5wPXAUTEL4FDgfZmFGhmZo1pJNBvBeZKmiNpAnAusLyqzV3AGQCS5pMC3WMqZmYjqG6gR8Ru4ELgRmA1cF1ErJR0maRFRbOLgNdJ+j/gWuBV0ao3uJuZjVENvQ+9eE/5iqp5l5RurwJOa25pZma2P/y5PTOzTDjQzcwy4UA3M8uEA93MLBMOdDOzTDjQzcwy4UA3M8uEA93MLBMOdDOzTDjQzcwy4UA3M8uEA93MLBMOdDOzTDjQzcwy4UA3M8uEA93MLBMOdDOzTDjQzcwy4UA3M8uEA93MLBMOdDOzTDjQzcwy4UA3M8uEA93MLBMOdDOzTDjQzcwy4UA3M8uEA93MLBMOdDOzTDjQzcwy4UA3M8uEA93MLBMOdDOzTDjQzcwy0VCgSzpL0hpJ3ZIWD9DmJZJWSVop6avNLdPMzOoZV6+BpDbgKuA5QA9wq6TlEbGq1GYu8C7gtIi4T9JjhqtgMzOrrZEe+kKgOyLWRsQjwDLgnKo2rwOuioj7ACJiU3PLNDOzehoJ9OnAutL9nmJe2fHA8ZJ+LulmSWfVWpGkCyR1Serq7e0dWsVmZlZTsy6KjgPmAqcD5wGfkTS5ulFELImIzojo7OjoaNKmzcwMGgv09cDM0v0ZxbyyHmB5ROyKiL8At5MC3szMRkgjgX4rMFfSHEkTgHOB5VVt/pvUO0dSO2kIZm0T6zQzszrqBnpE7AYuBG4EVgPXRcRKSZdJWlQ0uxHYImkV8GPg4ojYMlxFm5nZvhQRLdlwZ2dndHV1tWTbZmajlaTbIqKz1jJ/UtTMLBMOdDOzTDjQzcwy4UA3M8uEA93MLBMOdDOzTDjQzcwy4UA3M8uEA93MLBMOdDOzTDjQzcwy4UA3M8uEA93MLBMOdDOzTDjQzcwy4UA3M8uEA93MLBMOdDOzTDjQzcwy4UA3M8uEA93MLBMOdDOzTDjQzcwy4UA3M8uEA93MLBMOdDOzTDjQzcwy4UA3M8uEA93MLBMOdDOzTDjQzcwy4UA3M8uEA93MLBMOdDOzTDjQzcwy0VCgSzpL0hpJ3ZIWD9LuRZJCUmfzSjQzs0bUDXRJbcBVwNnAAuA8SQtqtJsEvBm4pdlFmplZfY300BcC3RGxNiIeAZYB59Ro9wHgCmBHE+szM7MGNRLo04F1pfs9xby/kvRUYGZEfGewFUm6QFKXpK7e3t79LtbMzAZ2wBdFJR0CfBy4qF7biFgSEZ0R0dnR0XGgmzYzs5JGAn09MLN0f0Yxr2IS8ETgJkl3ACcDy31h1MxsZDUS6LcCcyXNkTQBOBdYXlkYEVsjoj0iZkfEbOBmYFFEdA1LxWZmVlPdQI+I3cCFwI3AauC6iFgp6TJJi4a7QDMza8y4RhpFxApgRdW8SwZoe/qBl2VmZvvLnxQ1M8uEA93MLBMOdDOzTDjQzcwy4UA3M8uEA93MLBMOdDOzTDjQzcwy4UA3M8uEA93MLBMOdDOzTDjQzcwy4UA3M8uEA93MLBMOdDOzTDjQzcwy4UA3M8uEA93MLBMOdDOzTDjQzcwy4UA3M8uEA93MLBMOdDOzTDjQzcwy4UA3M8uEA93MLBMOdDOzTDjQzcwy4UA3M8uEA93MLBMOdDOzTDjQzcwy4UA3M8uEA93MLBMNBbqksyStkdQtaXGN5W+TtErS7yT9UNKxzS/VzMwGUzfQJbUBVwFnAwuA8yQtqGr2G6AzIp4EXA98pNmFmpnZ4BrpoS8EuiNibUQ8AiwDzik3iIgfR8RDxd2bgRnNLdPMzOppJNCnA+tK93uKeQM5H/hurQWSLpDUJamrt7e38SrNzKyupl4UlfRyoBP4aK3lEbEkIjojorOjo6OZmzYzG/PGNdBmPTCzdH9GMa8fSc8G3gM8MyJ2Nqc8MzNrVCM99FuBuZLmSJoAnAssLzeQ9BTg08CiiNjU/DLNzKyeuoEeEbuBC4EbgdXAdRGxUtJlkhYVzT4KTAS+Lum3kpYPsDozMxsmjQy5EBErgBVV8y4p3X52k+syM7P95E+KmpllwoFuZpYJB7qZWSYc6GZmmXCgm5llwoFuZpYJB7qZWSYc6GZmmXCgm5llwoFuZpYJB7qZWSYc6GZmmXCgm5llwoFuZpYJB7qZWSYc6GZmmXCgm5llwoFuZpYJB7qZWSYc6GZmmXCgm5llwoFuZpYJB7qZWSYc6GZmmXCgm5llwoFuZpYJB7qZWSYc6GZmmXCgm5llwoFuZpYJB7qZWSYc6GZmmXCgm5llwoFuZpYJB7qZWSYaCnRJZ0laI6lb0uIayx8l6WvF8lskzW52oWZmNri6gS6pDbgKOBtYAJwnaUFVs/OB+yLi8cAngCuaXaiZmQ2ukR76QqA7ItZGxCPAMuCcqjbnAEuL29cDZ0hS88o0M7N6xjXQZjqwrnS/BzhpoDYRsVvSVuBoYHO5kaQLgAuKu9slrRlK0UB79brHOO+P/rw/+nhf9JfD/jh2oAWNBHrTRMQSYMmBrkdSV0R0NqGkLHh/9Of90cf7or/c90cjQy7rgZml+zOKeTXbSBoHHAlsaUaBZmbWmEYC/VZgrqQ5kiYA5wLLq9osB/65uP1i4EcREc0r08zM6qk75FKMiV8I3Ai0AZ+LiJWSLgO6ImI58FngS5K6gXtJoT+cDnjYJjPeH/15f/Txvugv6/0hd6TNzPLgT4qamWXCgW5mlolRF+j1voZgrJA0U9KPJa2StFLSm1td08FAUpuk30j6dqtraTVJkyVdL+mPklZLOqXVNbWKpLcWr5M/SLpW0qGtrmk4jKpAb/BrCMaK3cBFEbEAOBl4wxjeF2VvBla3uoiDxCeB70XECcCJjNH9Imk68CagMyKeSHpzx3C/caMlRlWg09jXEIwJEXF3RPy6uL2N9GKd3tqqWkvSDOD5wDWtrqXVJB0JPIP0DjQi4pGIuL+1VbXUOODRxedkDgM2tLieYTHaAr3W1xCM6RADKL7d8inALa2tpOWuBN4B7G11IQeBOUAv8PliCOoaSYe3uqhWiIj1wMeAu4C7ga0R8f3WVjU8RlugWxVJE4FvAG+JiAdaXU+rSHoBsCkibmt1LQeJccBTgasj4inAg8CYvOYkaQrpTH4OMA04XNLLW1vV8Bhtgd7I1xCMGZLGk8L8KxFxQ6vrabHTgEWS7iANxT1L0pdbW1JL9QA9EVE5a7ueFPBj0bOBv0REb0TsAm4ATm1xTcNitAV6I19DMCYUX0/8WWB1RHy81fW0WkS8KyJmRMRs0t/FjyIiy15YIyJiI7BO0rxi1hnAqhaW1Ep3ASdLOqx43ZxBpheIR/TbFg/UQF9D0OKyWuU04BXA7yX9tpj37ohY0cKa7ODyRuArRednLfDqFtfTEhFxi6TrgV+T3h32GzL9CgB/9N/MLBOjbcjFzMwG4EA3M8uEA93MLBMOdDOzTDjQzcwy4UA3M8uEA93MLBP/D9nnK0lGP0WPAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfRXtSjp7W7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras \n",
        "# model = keras.models.Sequential()\n",
        "# model.add(layers.Dense(1000, input_shape=(x_train.shape[1],)))\n",
        "# model.add(layers.Dense(128, activation='relu '))\n",
        "# model.add(layers.Dense(64, activation='relu'))\n",
        "# model.add(layers.Dense(30, activation='softmax'))\n",
        "\n",
        "# model = keras.models.Sequential([\n",
        "#  keras.layers.Conv2D(128,4, activation=\"relu\", padding=\"same\", input_shape=[x_train.shape[1],x_train.shape[2],1]),\n",
        "#  keras.layers.MaxPooling2D(2),\n",
        "#  keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
        "#  keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
        "#  keras.layers.MaxPooling2D(2),\n",
        "#  keras.layers.Conv2D(512, 3, activation=\"relu\", padding=\"same\"),\n",
        "#  keras.layers.Conv2D(512, 3, activation=\"relu\", padding=\"same\"),\n",
        "#  keras.layers.MaxPooling2D(2),\n",
        "#  keras.layers.Flatten(),\n",
        "#  keras.layers.Dense(128, activation=\"relu\"),\n",
        "#  keras.layers.Dropout(0.5),\n",
        "#  keras.layers.Dense(64, activation=\"relu\"),\n",
        "#  keras.layers.Dropout(0.5),\n",
        "#  keras.layers.Dense(30, activation=\"softmax\")\n",
        "# ])\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "input_shape=(x_train.shape[1],x_train.shape[2],1)\n",
        "#1st hidden layer\n",
        "model.add(keras.layers.Conv2D(32, (3, 3), strides=(2, 2), input_shape=input_shape))\n",
        "model.add(keras.layers.AveragePooling2D((2, 2), strides=(2,2)))\n",
        "model.add(keras.layers.Activation('relu'))\n",
        "#2nd hidden layer\n",
        "model.add(keras.layers.Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(keras.layers.AveragePooling2D((2, 2), strides=(2,2)))\n",
        "model.add(keras.layers.Activation('relu'))\n",
        "#3rd hidden layer\n",
        "model.add(keras.layers.Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(keras.layers.AveragePooling2D((2, 2), strides=(2,2)))\n",
        "model.add(keras.layers.Activation('relu'))\n",
        "#Flatten\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dropout(rate=0.5))\n",
        "#Add fully connected layer.\n",
        "model.add(keras.layers.Dense(64))\n",
        "model.add(keras.layers.Activation('relu'))\n",
        "model.add(keras.layers.Dropout(rate=0.5))\n",
        "#Output layer\n",
        "model.add(keras.layers.Dense(30))\n",
        "model.add(keras.layers.Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_ZUyDglQ4DO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KoUlAke7iQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3icAFTw7j9o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "19f2b978-bbad-4c69-8f09-fa10999e256d"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test), batch_size=35) # about 64 epoch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 36481 samples, validate on 15636 samples\n",
            "Epoch 1/5\n",
            "36481/36481 [==============================] - 35s 953us/step - loss: 2.7755 - accuracy: 0.1882 - val_loss: 1.9900 - val_accuracy: 0.4456\n",
            "Epoch 2/5\n",
            "36481/36481 [==============================] - 34s 941us/step - loss: 2.0585 - accuracy: 0.3795 - val_loss: 1.4072 - val_accuracy: 0.6140\n",
            "Epoch 3/5\n",
            "36481/36481 [==============================] - 37s 1ms/step - loss: 1.6700 - accuracy: 0.4960 - val_loss: 1.0729 - val_accuracy: 0.6947\n",
            "Epoch 4/5\n",
            "36481/36481 [==============================] - 37s 1ms/step - loss: 1.4840 - accuracy: 0.5482 - val_loss: 0.9696 - val_accuracy: 0.7297\n",
            "Epoch 5/5\n",
            "36481/36481 [==============================] - 36s 984us/step - loss: 1.3668 - accuracy: 0.5871 - val_loss: 0.8973 - val_accuracy: 0.7452\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDXkLli9Ggoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SAVE CNN TO FS\n",
        "model.save(\"/content/drive/My Drive/best_audio_cnn_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g_tBW9BNrLL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "947e02ac-407e-4f55-d6a2-a058080d0bd5"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test), batch_size=35) # about 64 epoch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 36481 samples, validate on 15636 samples\n",
            "Epoch 1/5\n",
            "36481/36481 [==============================] - 36s 980us/step - loss: 0.6839 - accuracy: 0.7926 - val_loss: 0.4142 - val_accuracy: 0.8833\n",
            "Epoch 2/5\n",
            "36481/36481 [==============================] - 36s 983us/step - loss: 0.6799 - accuracy: 0.7923 - val_loss: 0.4068 - val_accuracy: 0.8812\n",
            "Epoch 3/5\n",
            "36481/36481 [==============================] - 34s 942us/step - loss: 0.6728 - accuracy: 0.7944 - val_loss: 0.4231 - val_accuracy: 0.8777\n",
            "Epoch 4/5\n",
            "36481/36481 [==============================] - 35s 968us/step - loss: 0.6798 - accuracy: 0.7915 - val_loss: 0.4048 - val_accuracy: 0.8821\n",
            "Epoch 5/5\n",
            "36470/36481 [============================>.] - ETA: 0s - loss: 0.6737 - accuracy: 0.7942"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3umUEVsKvLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# READ CNN FROM FS\n",
        "from keras.models import load_model\n",
        "import h5py\n",
        "model = tf.keras.models.load_model('/content/drive/My Drive/best_audio_cnn_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFHVwPA-juww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ynew = model.predict_classes(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLINwh_PlV03",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9cdd7347-f6ef-4270-83b3-62c40d6f345c"
      },
      "source": [
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "accuracy_score(y_test,ynew)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8844973138910207"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWSbCReMoH2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\n",
        "plot_confusion_matrix(model.fit_generator, x_test, y_test)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTHehVWSmutm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm = confusion_matrix(y_test, ynew)\n",
        "pd.DataFrame(cm, columns=range(30)).head(30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXysipkMnzVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "disp = plot_confusion_matrix(classifier, X_test, y_test,\n",
        "                                 display_labels=class_names,\n",
        "                                 cmap=plt.cm.Blues,\n",
        "                                 normalize=True)\n",
        "disp.ax_.set_title(title)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QZFaTIwm_pg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_pred = ynew\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2v6qKUEp76-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = {}\n",
        "models_history = []\n",
        "def save_model(name, model, persist=False):\n",
        "  if name not in models:\n",
        "    models[name]=[model]\n",
        "  else:\n",
        "    models[name].append(model)\n",
        "  \n",
        "  if len(models_history)>=10:\n",
        "    models_history.pop(0)\n",
        "  print(name + \" saved!\")\n",
        "  \n",
        "  if persist:\n",
        "    print(persist)\n",
        "\n",
        "  models_history.append((name,model))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjlB3SDp-X4g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "clf = GaussianMixture(n_components=30)\n",
        "l = clf.fit(x_train,y_train)\n",
        "save_model(\"GMM\",clf.fit(x_train,y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFdQOita7QnR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "clf = KNeighborsClassifier(n_neighbors=2).fit(x_train,y_train)\n",
        "# save_model(\"KNN\",clf.fit(x_train,y_train))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmd7hOP5LjqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_new = clf.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se8znPnMgQuG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "2f9ca228-0ecb-4bb1-ea76-4b8448f96c6d"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "report = accuracy_score(y_test, y_new)\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5625479662317728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N4w-fexlSBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCAXWR35g5El",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the model to disk\n",
        "import pickle\n",
        "filename = '/content/drive/My Drive/ModelliSalvati/Audio/Classificatori/KNN.sav'\n",
        "pickle.dump(clf, open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTXlEHQWOqk_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "af0d72d7-3c26-4261-88af-bfb4907267c7"
      },
      "source": [
        "print(\"ciao\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ciao\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fQhXCMVoCAf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "aa54b427-7a69-4efe-94de-92579cc621a7"
      },
      "source": [
        "from sklearn.naive_bayes import CategoricalNB\n",
        "clf = CategoricalNB(fit_prior=False)\n",
        "# save_model(\"CategoricalNB\",clf.fit(x_train,y_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CategoricalNB saved!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6zAIuOeYx_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dufCjuocq3UW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "40d66c09-be3c-4188-dce2-11681f6ae13c"
      },
      "source": [
        "from sklearn.neighbors import KernelDensity\n",
        "clf = KernelDensity(kernel=\"gaussian\", bandwidth=0.5)\n",
        "save_model(\"KernelDensity\",clf.fit(x_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KernelDensity saved!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9o6LkR9rQb6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "6bcd0623-3acb-48f9-a982-ac4254fff150"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "clf = AdaBoostClassifier(n_estimators=50, random_state=0, )\n",
        "save_model(\"adaboost\",clf.fit(x_train,y_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adaboost saved!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbxUMlowrSqW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7612bb75-7458-44a7-ba2f-2b03c8f2a677"
      },
      "source": [
        "# for m in models_history:\n",
        "#   print(m[0],end=\" \")\n",
        "#   print(m[1].score(x_test,y_test))\n",
        "print(models_history[len(models_history)-1][0])\n",
        "models_history[len(models_history)-1][1].score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adaboost\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1612576064908722"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6ZnvLE1kih-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "d41cc0db-fb26-4b86-fa1f-95b605ebbf81"
      },
      "source": [
        "from numpy import array\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import KernelDensity\n",
        "modelli = []\n",
        "def kfoldcv(classifier):\n",
        "  kf = KFold(n_splits=10,shuffle=True,random_state=43)\n",
        "  kf.get_n_splits(x) # RIMETTERE x PER CONSIDERARE TUTTO IL DATASET \n",
        "  scores = []\n",
        "  for train_index, test_index in kf.split(x):\n",
        "      print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index), end=\" \")\n",
        "      x_train_cv, x_test_cv = x[train_index], x[test_index]\n",
        "      y_train_cv, y_test_cv = y[train_index], y[test_index]\n",
        "      clf = classifier.fit(x_train_cv,y_train_cv)\n",
        "      s = clf.score(x_test_cv,y_test_cv)\n",
        "      scores.append(s)\n",
        "      modelli.append(clf)\n",
        "      print(s)\n",
        "  return np.array(scores),clf\n",
        "clfs = [\n",
        "        AdaBoostClassifier(n_estimators=50, random_state=0),\n",
        "        make_pipeline(StandardScaler(), SVC(gamma='auto')),\n",
        "        KNeighborsClassifier(n_neighbors=2),\n",
        "        CategoricalNB(fit_prior=False),\n",
        "        KernelDensity(kernel=\"gaussian\", bandwidth=0.5)\n",
        "]\n",
        "scores,clf = kfoldcv(clfs[4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN: 46905 TEST: 5212 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JIfl1Ina10b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "88b4df20-2b00-49cd-f7f9-fe2c159ba447"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(scores,scaley=False,color=\"b\")\n",
        "plt.title(\"KernelDensity KFOLD Cross Validation\")\n",
        "plt.savefig(\"/content/drive/My Drive/ModelliSalvati/Audio/Classificatori/KernelDensity.png\")\n",
        "import pickle\n",
        "filename = '/content/drive/My Drive/ModelliSalvati/Audio/Classificatori/KernelDensity.sav'\n",
        "pickle.dump(clf, open(filename, 'wb'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXz0lEQVR4nO3de7hcVX3G8e+bcxKQgIlCvJAEiBrEVG3RU0CogoKPASXx8VawXlAqVYtX1FJLEfCOPlZUtMY7dwP62FRTI1UQBaE5iFpDTI3hkgTUQyQJqJAEfv1jrSH7TGbO7IQ5mZx13s/zzHP27LVm7zVrZt5Ze+2ZOYoIzMxs7JvQ6waYmVl3ONDNzArhQDczK4QD3cysEA50M7NCONDNzArhQDcAJC2TdNTD3MZZki7qUpNsFyPpq5I+kJefLWlFnbo7uK97JT1hR28/XjnQdxGSbpV0TK/2HxF/ERFXd2t7kg6QFJIWN62/SNJZefkoSQ/mF++9ktZKOrvGNvvzdUn6tKRfSZou6SRJD1S2d6+kz1Ruf7ikH0i6R9IGSf8paU6l/ChJa9rs+6uSNuXb3iPpl5I+LGlKh344UNLlku7K+/yFpHdK6qvVkV0k6YT8PFPT+n5Jv5f0orrbiogfRcSTu9SuqyX9fdP294yIVd3Y/njiQB/nGuE4ig6VdPgI5XfkF++ewN8AJ0t6caeNSpoAfB44CjgyItbmop80tpcvp+b6zwK+B/wHsC8wC/g5cO12jATPjYi9gGnA64DD8u0nt2njE4EbgNXA0yJiCvByYADYq0X90X4svgVMBY5sWj8XCOC7o7x/G2UO9C6TNFPSNyUNSVrXGCFKemIeHa7Lo7WLJU3NZRcC+wH/mUeV78nrD5N0naT1kn5enRKRNEvSNXm0+N+Szq9Od0ial6dR1ucR0FMqZbdK+idJvwD+mEdoDx0hSOqT9F5Jv8nbv1HSzFx2nqTVkjbm9c/u0CXnAh+s03cRcQtwHTCnQ9U+4CukYDwqIn5XY/PnAhdExHkRcU9E/CEizgCuB86q075KO++LiKXAPGBvUri3cjZwXUS8MyLuzLddERGvjIj1lSOOkyXdDvxA0gRJZ0i6LY+aL2gcBUjaPR/hrMuP61JJj81lJ0lalR+vWyT9Xat2AwuB1zQVvQa4JCK25KOJ3+ajiWsk/UWrO9Z8NCPpYEk/zfv/OrB7pexRkr6dXxN35+UZueyDwLOBz6hyRJX75Ul5eUruh6HcL2fkN/TG/f6xpI/nbd8i6dgRHr6iOdC7KB9Gfxu4DTgAmA5c1igGPkwaHT4FmEkOkoh4NXA7cHweVZ4raTrwHeADwKOBdwHfkDQtb+8S4H9IgXIW8OpKOw4ELgXeThpNLia9WUyqNPdE4IXA1IjY0nRX3pnLjwMeCbwe+FMuWwr8VW7TJcDlknanvc8CB6rGdJKk2cARpJAdycXAk4HnRcS6GtvdAzgcuLxF8ULg+Z220UpE3ANcSQqkVo4BrqixqSNJz4kXACfly3OBJwB7Ao1po9cCU0jPnb2BNwJ/zkcInwKOzUcQhwM/a7OvrwEvk/QISGEJHJ/XA/wXMBt4DPBTUl+PKD+vvgVcSHpeXA68tFJlAukNeH/SwOXPjfsUEf8C/Ag4tXpE1eTT+X4/gdRXr2H4m+ihwApgH9Ib95ek4dNK40ZE+NKlC/AsYAjor1H3xcBNleu3AsdUrv8TcGHTbZaQXtT7AVuAPSplFwEX5eV/BRZWyiYAa0mj2ca+Xt+07Yf2T3pxzK95n+8G/jIvn1VpwwGkw/h+4M3A9ZV2npWXjwIeBNYDG3P9bwKT2uyrsc2NwGktyk/K/bK+cjkMmJFvd1CL28wFNlfas6bNvr8KfKDF+o8AV7a5zWZg7gh917g/T6is+z7w5sr1J+ft9JPeWK8Dnt60ncn5vr4UeESNx+zXwCvz8huAn7epNzW3b0pzH1T7CngOcAegym2va9VfueyvgLsr168G/r6pTgBPIh2NbQLmVMr+Abi68pivrJTtkW/7uIfzWh6rF4/Qu2smcFtsO+JF0mMlXaZ04m8jKdj2GWFb+wMvz4fW6yWtJ80xP540yv9DRPypUn91ZXlf0lECABHxYC6f3qZ+q/vxm1YFkt4laXk+JF9PGjmNdD8Avgg8VtLxLcruiIipEfFIUoD8ma2jxXZeBLxP0utblF2ft9e4XE9603mQ1HfNHg/c1WF/I5kO/KFN2bo2+2zW9rHLy/3AY0kj4CXAZZLukHSupIkR8Ufgb0kj9jslfUfSQSPs7wK2Tru8Ol9vTLV9JE+1bSS9yUPnx3dfYG3kRK20m7zdPSR9Pk+XbASuAaaq3onhfYCJbNsn1efybxsLldfEnjW2XRwHenetBvZT65NbHyKNHJ6Ww+tVpGmYhuafvVxNGqFXw2lyRHwEuBN4dJ5KaJhZWb6D9IYApE+D5PK1lToj/czmauCJzSvzfPl7gFcAj4qIqcCGpvuxjYjYRJpPfv9IdSNiA2kap1XwV12X65wn6ZUd6pID7yekE5LNXkEaFW83SXuSplV+1KbKfzN86qFtEyvLwx47th6N/S4iNkfE2RExhzSt8iJyMEfEkoh4PukN5FfAF0bY34XA0Uonig9j67TKK4H5+T5NIR1BQIfHl/R8nN40zbFfZfk00pHGofm5/5ym7Y70XLyLdITS3CdrW1cf3xzo3fU/pCf3RyRNziexjshlewH3Ahvy/Pi7m277O9IcYcNFwPGSXpBHTrvnE1EzIuI2YBA4S9Kk/MKshuBC4IWSjpY0kfSCup8UhHV8EXi/pNlKni5p73wftpCnlSSdSZpjr+NC0omyue0q5IA8AVjWaWMR8UPgJcACSXVC83TgtZLeKmmvfKLuA6RpsmEflcx9Xb00f8xvN0nPJM0b302aH27lfcDhkj4m6XH5tk9SOrE5tc1tLgXeoXTSe0/SQODrkU5YPlfS0/LIdiMp6B7MR3/z81z6/aTn2YPtOiIibgV+nPd1ZUQ0Rrh75duvI01dfKjdNpr8hPS8eKukiZJeAhxSKd+LdOS1XtKjc79UNT/3q219gPR8/mB+3PYnnePx9x1acKB3UX7yHU+a+7sdWEM6FIYUGs8gjWi/Q5orrvowcEaeXnlXRKwmjZbeSwrQ1aQ3gcZj9nekMFpHOnH6ddKLkYhYQToC+DRphHM86YTrppp35ROkF9H3SMHxJeARpMP97wL/RzrsvY+Rp24ekvvmTNJJs6p986cb7s3bfHS+b3W2eSWpf7/WZjqnWvfHpJOOLyG96d4GHAz8TUT8ulJ1Oil8qpfG0cp7JN1D6vMLgBuBw/MRQKt9/ob0GB0ALJO0AfgG6c34njZN/TLpze8a4BZSH78llz2OdJJ1I7Ac+GGuO4EUcneQpn+OBN40Un+QprX2z/ej4QJSv6wFbqbzyenG/dxE6teT8v7/luHP70+Snj935W02fzzyPNKJ2rslfarFLt4C/BFYRXojuoTUT9ZEw6e9bKxS+qjYryKiefRjZuOER+hjlKS/Vvps+wRJc0mj+W/1ul1m1jsdA13Sl5W+4PDLNuWS9ClJK5W+1vyM7jfTWngc6eNe95I+g/ymiLippy0ys57qOOUi6Tmk0LggIp7aovw40hzXcaQP+J8XEYeOQlvNzGwEHUfoEXEN7T9nC+lQ/4JIrid9vrTOZ2/NzKyLuvFjQNMZ/kmHNXndnc0VJZ0CnAIwefLkZx500EjffTAzs2Y33njjXRExrVXZaP+62zARsQBYADAwMBCDg4M7c/dmZmOepNvalXXjUy5rGf4txRn4W1xmZjtdNwJ9EfCa/GmXw4ANkX8q1MzMdp6OUy6SLiX9sto+Sr9//D7Sj+UQEf9O+mnW44CVpJ9Ybffb0GZmNoo6BnpEnNihPIB/7FqLzMxsh/ibomZmhXCgm5kVwoFuZlYIB7qZWSEc6GZmhXCgm5kVwoFuZlYIB7qZWSEc6GZmhXCgm5kVwoFuZlYIB7qZWSEc6GZmhXCgm5kVwoFuZlYIB7qZWSEc6GZmhXCgm5kVwoFuZlYIB7qZWSEc6GZmhXCgm5kVwoFuZlYIB7qZWSEc6GZmhXCgm5kVwoFuZlYIB7qZWSEc6GZmhXCgm5kVwoFuZlYIB7qZWSEc6GZmhXCgm5kVwoFuZlaIWoEuaa6kFZJWSjq9Rfl+kq6SdJOkX0g6rvtNNTOzkXQMdEl9wPnAscAc4ERJc5qqnQEsjIiDgROAz3a7oWZmNrI6I/RDgJURsSoiNgGXAfOb6gTwyLw8Bbije000M7M66gT6dGB15fqavK7qLOBVktYAi4G3tNqQpFMkDUoaHBoa2oHmmplZO906KXoi8NWImAEcB1woaZttR8SCiBiIiIFp06Z1addmZgb1An0tMLNyfUZeV3UysBAgIn4C7A7s040GmplZPXUCfSkwW9IsSZNIJz0XNdW5HTgaQNJTSIHuORUzs52oY6BHxBbgVGAJsJz0aZZlks6RNC9XOw14g6SfA5cCJ0VEjFajzcxsW/11KkXEYtLJzuq6MyvLNwNHdLdpZma2PfxNUTOzQjjQzcwK4UA3MyuEA93MrBAOdDOzQjjQzcwK4UA3MyuEA93MrBAOdDOzQjjQzcwK4UA3MyuEA93MrBAOdDOzQjjQzcwK4UA3MyuEA93MrBAOdDOzQjjQzcwK4UA3MyuEA93MrBAOdDOzQjjQzcwK4UA3MyuEA93MrBAOdDOzQjjQzcwK4UA3MyuEA93MrBAOdDOzQjjQzcwK4UA3MyuEA93MrBAOdDOzQjjQzcwKUSvQJc2VtELSSkmnt6nzCkk3S1om6ZLuNtPMzDrp71RBUh9wPvB8YA2wVNKiiLi5Umc28M/AERFxt6THjFaDzcystToj9EOAlRGxKiI2AZcB85vqvAE4PyLuBoiI33e3mWZm1kmdQJ8OrK5cX5PXVR0IHCjpWknXS5rbakOSTpE0KGlwaGhox1psZmYtdeukaD8wGzgKOBH4gqSpzZUiYkFEDETEwLRp07q0azMzg3qBvhaYWbk+I6+rWgMsiojNEXEL8H+kgDczs52kTqAvBWZLmiVpEnACsKipzrdIo3Mk7UOaglnVxXaamVkHHQM9IrYApwJLgOXAwohYJukcSfNytSXAOkk3A1cB746IdaPVaDMz25Yioic7HhgYiMHBwZ7s28xsrJJ0Y0QMtCrzN0XNzArhQDczK4QD3cysEA50M7NCONDNzArhQDczK4QD3cysEA50M7NCONDNzArhQDczK4QD3cysEA50M7NCONDNzArhQDczK4QD3cysEA50M7NCONDNzArhQDczK4QD3cysEA50M7NCONDNzArhQDczK4QD3cysEA50M7NCONDNzArhQDczK4QD3cysEA50M7NCONDNzArhQDczK4QD3cysEA50M7NCONDNzArhQDczK4QD3cysELUCXdJcSSskrZR0+gj1XiopJA10r4lmZlZHx0CX1AecDxwLzAFOlDSnRb29gLcBN3S7kWZm1lmdEfohwMqIWBURm4DLgPkt6r0f+ChwXxfbZ2ZmNdUJ9OnA6sr1NXndQyQ9A5gZEd8ZaUOSTpE0KGlwaGhouxtrZmbtPeyTopImAJ8ATutUNyIWRMRARAxMmzbt4e7azMwq6gT6WmBm5fqMvK5hL+CpwNWSbgUOAxb5xKiZ2c5VJ9CXArMlzZI0CTgBWNQojIgNEbFPRBwQEQcA1wPzImJwVFpsZmYtdQz0iNgCnAosAZYDCyNimaRzJM0b7QaamVk9/XUqRcRiYHHTujPb1D3q4TfLzMy2l78pamZWCAe6mVkhHOhmZoVwoJuZFcKBbmZWCAe6mVkhHOhmZoVwoJuZFcKBbmZWCAe6mVkhHOhmZoVwoJuZFcKBbmZWCAe6mVkhHOhmZoVwoJuZFcKBbmZWCAe6mVkhHOhmZoVwoJuZFcKBbmZWCAe6mVkhHOhmZoVwoJuZFcKBbmZWCAe6mVkhHOhmZoVwoJuZFcKBbmZWCAe6mVkhHOhmZoVwoJuZFcKBbmZWCAe6mVkhagW6pLmSVkhaKen0FuXvlHSzpF9I+r6k/bvfVDMzG0nHQJfUB5wPHAvMAU6UNKep2k3AQEQ8HbgCOLfbDTUzs5HVGaEfAqyMiFURsQm4DJhfrRARV0XEn/LV64EZ3W2mmZl1UifQpwOrK9fX5HXtnAz8V6sCSadIGpQ0ODQ0VL+VZmbWUVdPikp6FTAAfKxVeUQsiIiBiBiYNm1aN3dtZjbu9deosxaYWbk+I68bRtIxwL8AR0bE/d1pnpmZ1VVnhL4UmC1plqRJwAnAomoFSQcDnwfmRcTvu99MMzPrpGOgR8QW4FRgCbAcWBgRyySdI2lervYxYE/gckk/k7SozebMzGyU1JlyISIWA4ub1p1ZWT6my+0yM7Pt5G+KmpkVwoFuZlYIB7qZWSEc6GZmhXCgm5kVwoFuZlYIB7qZWSEc6GZmhXCgm5kVwoFuZlYIB7qZWSEc6GZmhXCgm5kVwoFuZlYIB7qZWSEc6GZmhXCgm5kVwoFuZlYIB7qZWSEc6GZmhXCgm5kVwoFuZlYIB7qZWSEc6GZmhXCgm5kVwoFuZlYIB7qZWSEc6GZmhXCgm5kVwoFuZlaI/l43wMxsV/Hgg+nywAOj+3f2bJg+vfvtH3OBfu21cOWVaVlKl07Lo123lyK2PlGqly1btl23I+u35zYTJ8Luu8Nuu438t1tl/V1+9rbqy1Z926msEQr9/dteJk5svb6/H/r6ev98avbAA7B5c7ps2rTtct11mzen58tIl51Rp9VjVw3aneVzn4M3vrH72x1zgX7ddXD22b1uxdghpaDo69saGs2X7V0/aVLrsi1b4L770mXjxvT3/vuH/21cuvHi6evbNux32234KGt7Q7jX+vpGDv06bwzVOrD9gVxd3ll9MmHC9t+36vU99uhcp/GcnjAhLTf/bbVutP4eeODo9KMiYnS23MHAwEAMDg7u8O0j0qXT8mjX3RVUn5DNQbyrjfgatmxpHfbN63akrNULtXrZ3vU7chtp61HMzhyBNteJSME2aVL62255R8q35zaNgG0V1o1+tHok3RgRA63KxtwIvaE6/WFjT+PFPHlyr1tiVo5a74uS5kpaIWmlpNNblO8m6eu5/AZJB3S7oWZmNrKOgS6pDzgfOBaYA5woaU5TtZOBuyPiScC/AR/tdkPNzGxkdUbohwArI2JVRGwCLgPmN9WZD3wtL18BHC15QsTMbGeqM4c+HVhdub4GOLRdnYjYImkDsDdwV7WSpFOAU/LVeyWt2JFGA/s0b3ucc38M5/7Yyn0xXAn9sX+7gp16UjQiFgALHu52JA22O8s7Hrk/hnN/bOW+GK70/qgz5bIWmFm5PiOva1lHUj8wBVjXjQaamVk9dQJ9KTBb0ixJk4ATgEVNdRYBr83LLwN+EL36gLuZ2TjVccolz4mfCiwB+oAvR8QySecAgxGxCPgScKGklcAfSKE/mh72tE1h3B/DuT+2cl8MV3R/9OybomZm1l3+wq2ZWSEc6GZmhRhzgd7pZwjGC0kzJV0l6WZJyyS9rddt2hVI6pN0k6Rv97otvSZpqqQrJP1K0nJJz+p1m3pF0jvy6+SXki6VtHuv2zQaxlSg1/wZgvFiC3BaRMwBDgP+cRz3RdXbgOW9bsQu4jzguxFxEPCXjNN+kTQdeCswEBFPJX24Y7Q/uNETYyrQqfczBONCRNwZET/Ny/eQXqyj8D9Qxg5JM4AXAl/sdVt6TdIU4DmkT6AREZsiYn1vW9VT/cAj8vdk9gDu6HF7RsVYC/RWP0MwrkMMIP+65cHADb1tSc99EngPsAv8q4qemwUMAV/JU1BflDQuf6w4ItYCHwduB+4ENkTE93rbqtEx1gLdmkjaE/gG8PaI2Njr9vSKpBcBv4+IG3vdll1EP/AM4HMRcTDwR2BcnnOS9CjSkfwsYF9gsqRX9bZVo2OsBXqdnyEYNyRNJIX5xRHxzV63p8eOAOZJupU0Ffc8SRf1tkk9tQZYExGNo7YrSAE/Hh0D3BIRQxGxGfgmcHiP2zQqxlqg1/kZgnEh/zzxl4DlEfGJXren1yLinyNiRkQcQHpe/CAiihyF1RERvwVWS3pyXnU0cHMPm9RLtwOHSdojv26OptATxGPqX9C1+xmCHjerV44AXg38r6Sf5XXvjYjFPWyT7VreAlycBz+rgNf1uD09ERE3SLoC+Cnp02E3UehPAPir/2ZmhRhrUy5mZtaGA93MrBAOdDOzQjjQzcwK4UA3MyuEA93MrBAOdDOzQvw/evcJNsEcFxUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTaLkXgSzGkC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "f2a297e1-6b53-4708-c7ca-22a112e3bb8f"
      },
      "source": [
        "clf = SVC(gamma='auto')\n",
        "clf.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGPGGsz0bm7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = pd.DataFrame(data=[scores,scores-0.2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAondmPLb22J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "c360cd17-ea73-43ac-de58-d3c954097abf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.60019175, 0.59348035, 0.57813998, 0.59117083, 0.62955854,\n",
              "        0.62092131, 0.60556622, 0.63147793, 0.61228407, 0.61708253]),\n",
              " array([0.40019175, 0.39348035, 0.37813998, 0.39117083, 0.42955854,\n",
              "        0.42092131, 0.40556622, 0.43147793, 0.41228407, 0.41708253])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80A9lpvqbJ7S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "a59ed532-23d5-4a1e-ef50-202e3348953c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(scores,scaley=False,color=\"b\")\n",
        "plt.title(\"SVM KFOLD Cross Validation\")\n",
        "plt.savefig(\"/content/drive/My Drive/ModelliSalvati/Audio/Classificatori/svm.png\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpCkgAJy00OH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the model to disk\n",
        "import pickle\n",
        "filename = '/content/drive/My Drive/ModelliSalvati/Audio/Classificatori/svm.sav'\n",
        "pickle.dump(clf, open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6GQqeAkW4HA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import array\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# def kfoldcv(classifier):\n",
        "kf = KFold(n_splits=10,shuffle=True,random_state=43)\n",
        "kf.get_n_splits(x) # RIMETTERE x PER CONSIDERARE TUTTO IL DATASET \n",
        "scores = []\n",
        "for train_index, test_index in kf.split(x):\n",
        "    print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index), end=\" \")\n",
        "    x_train_cv, x_test_cv = x[train_index], x[test_index]\n",
        "    y_train_cv, y_test_cv = y.iloc[train_index], y.iloc[test_index]\n",
        "    # clf = classifier.fit(x_train_cv,y_train_cv)\n",
        "    model = getNewModel()\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='sgd', metrics=['accuracy'])\n",
        "    model.fit(x_train_cv,  y_train_cv, epochs=65)\n",
        "    s = model.evaluate(x_test_cv, y_test_cv, verbose=0)\n",
        "    scores.append(s)\n",
        "    modelli.append(model)\n",
        "    print(s)\n",
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAHvwTx9loeE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "clf = clf.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8d4wyTLrtC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ice-GAnm6_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}